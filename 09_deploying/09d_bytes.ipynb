{"cells": [{"cell_type": "code", "execution_count": 4, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 72}, "id": "hiQ6zAoYhyaA", "outputId": "0acee878-1207-42c3-9bee-a594acd44365"}, "outputs": [{"data": {"text/markdown": ["\n", "<table class=\"tfo-notebook-buttons\" align=\"left\">\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=Handling image bytes&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F09_deploying%2F09d_bytes.ipynb&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F09_deploying%2F09d_bytes.ipynb\">\n", "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n", "  </td>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09d_bytes.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09d_bytes.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n", "  </td>\n", "  <td>\n", "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/09_deploying/09d_bytes.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n", "  </td>\n", "</table>\n"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["from IPython.display import Markdown as md\n", "\n", "### change to reflect your notebook\n", "_nb_loc = \"09_deploying/09d_bytes.ipynb\"\n", "_nb_title = \"Handling image bytes\"\n", "\n", "### no need to change any of this\n", "_nb_safeloc = _nb_loc.replace('/', '%2F')\n", "md(\"\"\"\n", "<table class=\"tfo-notebook-buttons\" align=\"left\">\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name={1}&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F{2}&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F{2}\">\n", "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n", "  </td>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n", "  </td>\n", "  <td>\n", "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n", "  </td>\n", "</table>\n", "\"\"\".format(_nb_loc, _nb_title, _nb_safeloc))"]}, {"cell_type": "markdown", "metadata": {"id": "a8HQYsAtC0Fv"}, "source": ["# \u753b\u50cf\u30d0\u30a4\u30c8\u306e\u51e6\u7406  \n", "\n", "\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001(\u7b2c7\u7ae0\u306e\u3088\u3046\u306b)\u3059\u3067\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u306e\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u304b\u3089\u958b\u59cb\u3057\u307e\u3059\u3002  \n", "\u4fbf\u5b9c\u4e0a\u3001\u3053\u306e\u30e2\u30c7\u30eb\u3092gs\uff1a//practical-ml-vision-book/flowers_5_trained\u306e\u30d1\u30d6\u30ea\u30c3\u30af\u30d0\u30b1\u30c3\u30c8\u306b\u914d\u7f6e\u3057\u307e\u3057\u305f  \n", "\n", "\u79c1\u305f\u3061\u304c\u3084\u308a\u305f\u3044\u306e\u306f\u3001\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4ecb\u3057\u3066\u30d0\u30a4\u30c8\u3092\u76f4\u63a5\u51e6\u7406\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u305d\u3046\u3059\u308c\u3070\u3001\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306f\u753b\u50cf\u3092Google CloudStorage\u306b\u7f6e\u304f\u5fc5\u8981\u304c\u306a\u304f\u306a\u308a\u307e\u3059\u3002"]}, {"cell_type": "markdown", "metadata": {"id": "5UOm2etrwYCs"}, "source": ["## GPU\u3092\u6709\u52b9\u306b\u3057\u3001\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\u3092\u8a2d\u5b9a\u3057\u307e\u3059  \n", "\n", "\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3068\u3001\u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u5185\u306e\u4ed6\u306e\u307b\u3068\u3093\u3069\u3059\u3079\u3066\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af  \n", "GPU\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u3088\u308a\u9ad8\u901f\u306b\u5b9f\u884c\u3055\u308c\u307e\u3059\u3002  \n", "Colab\u306b\u3064\u3044\u3066\uff1a  \n", "- [\u7de8\u96c6]\u2192[\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u8a2d\u5b9a]\u306b\u79fb\u52d5\u3057\u307e\u3059  \n", "- [\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30a2\u30af\u30bb\u30e9\u30ec\u30fc\u30bf]\u30c9\u30ed\u30c3\u30d7\u30c0\u30a6\u30f3\u304b\u3089[GPU]\u3092\u9078\u629e\u3057\u307e\u3059  \n", "\n", "\u30af\u30e9\u30a6\u30c9AI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\uff1a  \n", "- https://console.cloud.google.com/ai-platform/notebooks\u306b\u79fb\u52d5\u3057\u307e\u3059  \n", "- GPU\u3092\u4f7f\u7528\u3057\u3066\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\u3059\u308b\u304b\u3001\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u9078\u629e\u3057\u3066GPU\u3092\u8ffd\u52a0\u3057\u307e\u3059  \n", "\n", "\u6b21\u306b\u3001\u30c6\u30f3\u30bd\u30eb\u30d5\u30ed\u30fc\u3092\u4f7f\u7528\u3057\u3066GPU\u306b\u63a5\u7d9a\u3067\u304d\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ugGJcxKAwhc2", "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"}, "outputs": [], "source": ["import tensorflow as tf\n", "print('TensorFlow version' + tf.version.VERSION)\n", "print('Built with GPU support? ' + ('Yes!' if tf.test.is_built_with_cuda() else 'Noooo!'))\n", "print('There are {} GPUs'.format(len(tf.config.experimental.list_physical_devices(\"GPU\"))))\n", "device_name = tf.test.gpu_device_name()\n", "if device_name != '/device:GPU:0':\n", "    raise SystemError('GPU device not found')\n", "print('Found GPU at: {}'.format(device_name))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u304b\u3089\u8aad\u307f\u53d6\u308a\u307e\u3059\u3002  \n", "\n", "\u7f72\u540d\u3060\u3051\u3067\u306a\u304f\u5b8c\u5168\u306a\u30e2\u30c7\u30eb\u304c\u5fc5\u8981\u306a\u305f\u3081\u3001\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u3067\u306f\u306a\u304f*\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8*\u304b\u3089\u958b\u59cb\u3057\u307e\u3059\u3002"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model: \"flower_classification\"\n", "_________________________________________________________________\n", "Layer (type)                 Output Shape              Param #   \n", "=================================================================\n", "random/center_crop (RandomCr (None, 224, 224, 3)       0         \n", "_________________________________________________________________\n", "random_lr_flip/none (RandomF (None, 224, 224, 3)       0         \n", "_________________________________________________________________\n", "mobilenet_embedding (KerasLa (None, 1280)              2257984   \n", "_________________________________________________________________\n", "dense_hidden (Dense)         (None, 32)                40992     \n", "_________________________________________________________________\n", "flower_prob (Dense)          (None, 5)                 165       \n", "=================================================================\n", "Total params: 2,299,141\n", "Trainable params: 2,265,029\n", "Non-trainable params: 34,112\n", "_________________________________________________________________\n", "None\n"]}], "source": ["import os\n", "import shutil\n", "import tensorflow as tf\n", "\n", "CHECK_POINT_DIR='gs://practical-ml-vision-book/flowers_5_trained/chkpts'\n", "model = tf.keras.models.load_model(CHECK_POINT_DIR)\n", "print(model.summary())"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["IMG_HEIGHT = 345\n", "IMG_WIDTH = 345\n", "IMG_CHANNELS = 3\n", "CLASS_NAMES = 'daisy dandelion roses sunflowers tulips'.split()\n", "\n", "def read_from_jpegfile(filename):\n", "    img_bytes = tf.io.read_file(filename)\n", "    return img_bytes\n", "    \n", "def preprocess(img_bytes):\n", "    img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n", "    img = tf.image.convert_image_dtype(img, tf.float32)\n", "    return tf.image.resize_with_pad(img, IMG_HEIGHT, IMG_WIDTH)"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[[0.3507376  0.3983379  0.02309519 0.07595135 0.15187794]]\n", "[[3.1782882e-05 9.9996090e-01 5.1874702e-07 3.2268999e-06 3.5444552e-06]]\n", "[[9.9471879e-01 3.5855272e-03 2.1374140e-05 1.5876008e-03 8.6639280e-05]]\n", "[[1.5454909e-03 2.2907292e-04 3.6099207e-02 3.1195192e-03 9.5900667e-01]]\n", "[[4.7941930e-06 3.9310632e-07 5.8220904e-02 9.1497981e-07 9.4177294e-01]]\n"]}], "source": ["filenames = [\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'\n", "]\n", "for filename in filenames:\n", "    img_bytes = read_from_jpegfile(filename)\n", "    img = preprocess(img_bytes)\n", "    img = tf.expand_dims(img, axis=0)\n", "    pred = model.predict(img)\n", "    print(pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u306e\u30d0\u30a4\u30c8\u3092\u51e6\u7406\u3059\u308b\u7f72\u540d\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3057\u307e\u3059"]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Assets written to: export/flowers_model3/assets\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:Assets written to: export/flowers_model3/assets\n"]}], "source": ["@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n", "def predict_bytes(img_bytes):\n", "    input_images = tf.map_fn(\n", "        preprocess,\n", "        img_bytes,\n", "        fn_output_signature=tf.float32\n", "    )\n", "    batch_pred = model(input_images) # same as model.predict()\n", "    top_prob = tf.math.reduce_max(batch_pred, axis=[1])\n", "    pred_label_index = tf.math.argmax(batch_pred, axis=1)\n", "    pred_label = tf.gather(tf.convert_to_tensor(CLASS_NAMES), pred_label_index)\n", "    return {\n", "        'probability': top_prob,\n", "        'flower_type_int': pred_label_index,\n", "        'flower_type_str': pred_label\n", "    }\n", "\n", "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n", "def predict_filename(filenames):\n", "    img_bytes = tf.map_fn(\n", "        tf.io.read_file,\n", "        filenames\n", "    )\n", "    result = predict_bytes(img_bytes)\n", "    result['filename'] = filenames\n", "    return result\n", "\n", "shutil.rmtree('export', ignore_errors=True)\n", "os.mkdir('export')\n", "model.save('export/flowers_model3',\n", "          signatures={\n", "              'serving_default': predict_filename,\n", "              'from_bytes': predict_bytes\n", "          })"]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n", "SignatureDef key: \"__saved_model_init_op\"\n", "SignatureDef key: \"from_bytes\"\n", "SignatureDef key: \"serving_default\"\n"]}], "source": ["!saved_model_cli show --tag_set serve --dir export/flowers_model3"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel SignatureDef contains the following input(s):\n", "  inputs['filenames'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: serving_default_filenames:0\n", "The given SavedModel SignatureDef contains the following output(s):\n", "  outputs['filename'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall_1:0\n", "  outputs['flower_type_int'] tensor_info:\n", "      dtype: DT_INT64\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall_1:1\n", "  outputs['flower_type_str'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall_1:2\n", "  outputs['probability'] tensor_info:\n", "      dtype: DT_FLOAT\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall_1:3\n", "Method name is: tensorflow/serving/predict\n"]}], "source": ["!saved_model_cli show --tag_set serve --dir export/flowers_model3 --signature_def serving_default"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel SignatureDef contains the following input(s):\n", "  inputs['img_bytes'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: from_bytes_img_bytes:0\n", "The given SavedModel SignatureDef contains the following output(s):\n", "  outputs['flower_type_int'] tensor_info:\n", "      dtype: DT_INT64\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:0\n", "  outputs['flower_type_str'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:1\n", "  outputs['probability'] tensor_info:\n", "      dtype: DT_FLOAT\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:2\n", "Method name is: tensorflow/serving/predict\n"]}], "source": ["!saved_model_cli show --tag_set serve --dir export/flowers_model3 --signature_def from_bytes"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## img\u30d0\u30a4\u30c8\u3092\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u7d4c\u7531\u3067\u9001\u4fe1\u3059\u308b  \n", "\n", "GCS\u306b\u4e2d\u9593\u30d5\u30a1\u30a4\u30eb\u306f\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002\u5358\u306bPython\u306e\u30d5\u30a1\u30a4\u30eb\u8aad\u307f\u53d6\u308a\u65b9\u6cd5\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Copying gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg...\n", "/ [1 files][ 19.4 KiB/ 19.4 KiB]                                                \n", "Operation completed over 1 objects/19.4 KiB.                                     \n"]}], "source": ["!gsutil cp gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg /tmp/test.jpg"]}, {"cell_type": "code", "execution_count": 33, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'probability': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.9947188], dtype=float32)>, 'flower_type_str': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'daisy'], dtype=object)>, 'flower_type_int': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>}\n"]}], "source": ["with open('/tmp/test.jpg', 'rb') as ifp:\n", "    img_bytes = ifp.read()\n", "    serving_fn = tf.keras.models.load_model('./export/flowers_model3').signatures['from_bytes']\n", "    pred = serving_fn(tf.convert_to_tensor([img_bytes]))\n", "    print(pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u30d0\u30a4\u30c8\u51e6\u7406\u30e2\u30c7\u30eb\u3092CAIP\u306b\u30c7\u30d7\u30ed\u30a4\u3057\u307e\u3059"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Copying file://./export/flowers_model3/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n", "Copying file://./export/flowers_model3/variables/variables.index [Content-Type=application/octet-stream]...\n", "Copying file://./export/flowers_model3/saved_model.pb [Content-Type=application/octet-stream]...\n", "/ [3/3 files][ 10.7 MiB/ 10.7 MiB] 100% Done                                    \n", "Operation completed over 3 objects/10.7 MiB.                                     \n"]}], "source": ["%%bash\n", "BUCKET=\"ai-analytics-solutions-mlvisionbook\"  # CHANGE\n", "gsutil -m cp -r ./export/flowers_model3 gs://${BUCKET}/flowers_model3"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Deploying model bytes\n", "Creating bytes endpoint now.\n", "The endpoint_id is 7318683646011899904\n", "Uploading bytes model now.\n", "The model_id is 2990680423643742208\n", "Deploying model now\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [1561614649575604224]...\n", ".....done.\n", "Created Vertex AI endpoint: projects/563535018348/locations/us-central1/endpoints/7318683646011899904.\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [8091834109262823424]...\n", ".....done.\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [3867457658789298176]...\n", "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n", "Deployed a model to the endpoint 7318683646011899904. Id of the deployed model: 6992243041771716608.\n"]}], "source": ["%%bash\n", "BUCKET=\"ai-analytics-solutions-mlvisionbook\" # CHANGE\n", "./vertex_deploy.sh \\\n", "--endpoint_name=bytes \\\n", "--model_name=bytes \\\n", "--model_location=gs://${BUCKET}/flowers_model3"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u91cd\u8981\uff1a\u3053\u306e\u30bb\u30eb\u3092\u5909\u66f4\u3059\u308b  \n", "\n", "\u4e0a\u8a18\u306e\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8ID\u3068\u30c7\u30d7\u30ed\u30a4\u3055\u308c\u305f\u30e2\u30c7\u30ebID\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u4e0b\u306e\u30bb\u30eb\u306b\u8a2d\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# CHANGE THESE TO REFLECT WHERE YOU DEPLOYED THE MODEL\n", "import os\n", "os.environ['ENDPOINT_ID'] = '7318683646011899904' # CHANGE\n", "os.environ['MODEL_ID'] = '6992243041771716608' # CHANGE\n", "os.environ['PROJECT'] = 'ai-analytics-solutions' # CHANGE\n", "os.environ['BUCKET'] = 'ai-analytics-solutions-mlvisionbook' # CHANGE\n", "os.environ['REGION'] = 'us-central1' # CHANGE"]}, {"cell_type": "code", "execution_count": 43, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Copying gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg...\n", "/ [1 files][ 19.4 KiB/ 19.4 KiB]                                                \n", "Operation completed over 1 objects/19.4 KiB.                                     \n", "Copying gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg...\n", "/ [1 files][ 34.6 KiB/ 34.6 KiB]                                                \n", "Operation completed over 1 objects/34.6 KiB.                                     \n"]}], "source": ["%%bash\n", "gsutil cp gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg /tmp/test1.jpg\n", "gsutil cp gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg /tmp/test2.jpg"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Base64\u3067\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u305f\u30c7\u30fc\u30bf\u3092\u6e21\u3059\u65b9\u6cd5\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b'{\\n  \"error\": {\\n    \"code\": 400,\\n    \"message\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\",\\n    \"status\": \"INVALID_ARGUMENT\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\\n        \"fieldViolations\": [\\n          {\\n            \"description\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\"\\n          }\\n        ]\\n      }\\n    ]\\n  }\\n}\\n'\n"]}], "source": ["# Invoke from Python.\n", "import base64\n", "import json\n", "from oauth2client.client import GoogleCredentials\n", "import requests\n", "\n", "PROJECT = \"ai-analytics-solutions\"  # CHANGE\n", "REGION = \"us-central1\"  # make sure you have GPU/TPU quota in this region\n", "ENDPOINT_ID = \"7318683646011899904\"\n", "\n", "def b64encode(filename):\n", "    with open(filename, 'rb') as ifp:\n", "        img_bytes = ifp.read()\n", "        return base64.b64encode(img_bytes)\n", "\n", "token = GoogleCredentials.get_application_default().get_access_token().access_token\n", "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n", "    REGION, PROJECT, REGION, ENDPOINT_ID)\n", "headers = {\"Authorization\": \"Bearer \" + token }\n", "data = {\n", "    \"signature_name\": \"from_bytes\",  # currently bugged\n", "    \"instances\": [\n", "        {\n", "            \"img_bytes\": {\"b64\": b64encode('/tmp/test1.jpg')}\n", "        },\n", "        {\n", "            \"img_bytes\": {\"b64\": b64encode('/tmp/test2.jpg')}\n", "        },\n", "    ]\n", "}\n", "response = requests.post(api, json=data, headers=headers)\n", "print(response.content)"]}, {"cell_type": "markdown", "metadata": {"id": "Duu8mX3iXANE"}, "source": ["## \u30e9\u30a4\u30bb\u30f3\u30b9  \n", "Copyright 2020 Google Inc. Apache License\u30d0\u30fc\u30b8\u30e7\u30f32.0(\u300c\u30e9\u30a4\u30bb\u30f3\u30b9\u300d)\u306b\u57fa\u3065\u3044\u3066\u30e9\u30a4\u30bb\u30f3\u30b9\u4f9b\u4e0e\u3055\u308c\u307e\u3059\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u6e96\u62e0\u3059\u308b\u5834\u5408\u3092\u9664\u304d\u3001\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u30b3\u30d4\u30fc\u306fhttp://www.apache.org/licenses/LICENSE-2.0\u3067\u5165\u624b\u3067\u304d\u307e\u3059\u3002\u9069\u7528\u6cd5\u3067\u8981\u6c42\u3055\u308c\u3066\u3044\u308b\u304b\u3001\u66f8\u9762\u3067\u5408\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u9650\u308a\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u3044\u3066\u914d\u5e03\u3055\u308c\u308b\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306f\u300c\u73fe\u72b6\u6709\u59ff\u300d\u3067\u914d\u5e03\u3055\u308c\u307e\u3059\u3002\u660e\u793a\u307e\u305f\u306f\u9ed9\u793a\u3092\u554f\u308f\u305a\u3001\u3044\u304b\u306a\u308b\u7a2e\u985e\u306e\u4fdd\u8a3c\u307e\u305f\u306f\u6761\u4ef6\u3082\u3042\u308a\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u304f\u8a31\u53ef\u3068\u5236\u9650\u3092\u898f\u5b9a\u3059\u308b\u7279\u5b9a\u306e\u8a00\u8a9e\u306b\u3064\u3044\u3066\u306f\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": ["5UOm2etrwYCs"], "name": "03a_transfer_learning.ipynb", "provenance": [], "toc_visible": true}, "environment": {"kernel": "python3", "name": "tf2-gpu.2-8.m90", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m90"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 4}