{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "hiQ6zAoYhyaA",
    "outputId": "0acee878-1207-42c3-9bee-a594acd44365"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?name=Changing+signatures+of+exported+model&download_url=https%3A%2F%2Fgithub.com%2Ftakumiohym%2Fpractical-ml-vision-book-ja%2Fraw%2Fmaster%2F09_deploying%2F09c_changesig.ipynb\"><img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/>Run in Vertex AI Workbench</a></td><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/takumiohym/practical-ml-vision-book-ja/blob/master/09_deploying/09c_changesig.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"https://github.com/takumiohym/practical-ml-vision-book-ja/blob/master/09_deploying/09c_changesig.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td><td><a href=\"https://raw.githubusercontent.com/takumiohym/practical-ml-vision-book-ja/master/09_deploying/09c_changesig.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a></td></table><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "### change to reflect your notebook\n",
    "_nb_loc = \"09_deploying/09c_changesig.ipynb\"\n",
    "_nb_title = \"Changing signatures of exported model\"\n",
    "\n",
    "_icons=[\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\", \"https://www.tensorflow.org/images/colab_logo_32px.png\", \"https://www.tensorflow.org/images/GitHub-Mark-32px.png\", \"https://www.tensorflow.org/images/download_logo_32px.png\"]\n",
    "_links=[\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?\" + urllib.parse.urlencode({\"name\": _nb_title, \"download_url\": \"https://github.com/takumiohym/practical-ml-vision-book-ja/raw/master/\"+_nb_loc}), \"https://colab.research.google.com/github/takumiohym/practical-ml-vision-book-ja/blob/master/{0}\".format(_nb_loc), \"https://github.com/takumiohym/practical-ml-vision-book-ja/blob/master/{0}\".format(_nb_loc), \"https://raw.githubusercontent.com/takumiohym/practical-ml-vision-book-ja/master/{0}\".format(_nb_loc)]\n",
    "md(\"\"\"<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"{0}\"><img src=\"{4}\"/>Run in Vertex AI Workbench</a></td><td><a target=\"_blank\" href=\"{1}\"><img src=\"{5}\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"{2}\"><img src=\"{6}\" />View source on GitHub</a></td><td><a href=\"{3}\"><img src=\"{7}\" />Download notebook</a></td></table><br/><br/>\"\"\".format(_links[0], _links[1], _links[2], _links[3], _icons[0], _icons[1], _icons[2], _icons[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# エクスポートされたモデルのSignatureの変更  \n",
    "\n",
    "このノートブックでは、学習済みでエクスポートされたモデルから始めます。  \n",
    "このモデルはパブリックの`gs://practical-ml-vision-book/flowers_5_trained`に保存されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エクスポートされたモデルを読み込みます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOCATION='gs://practical-ml-vision-book/flowers_5_trained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://practical-ml-vision-book/flowers_5_trained/saved_model.pb\n",
      "gs://practical-ml-vision-book/flowers_5_trained/chkpts/\n",
      "gs://practical-ml-vision-book/flowers_5_trained/variables/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:27:44.322073: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 21:27:44.322125: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['filenames'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_filenames:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['flower_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "  outputs['flower_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:1\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:2\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --signature_def serving_default --dir {MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パススルーパラメータを追加する  \n",
    "\n",
    "上記のSignatureは入力ファイル名を出力してくれませんので、追加してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:27:47.488458: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 21:27:47.488510: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:27:49.654406: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-17 21:27:49.654453: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-17 21:27:49.654480: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tpu-direct): /proc/driver/nvidia/version does not exist\n",
      "2022-07-17 21:27:49.654756: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-17 21:27:57.425630: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/flowers_model/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(MODEL_LOCATION)\n",
    "old_fn = model.signatures['serving_default']\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
    "def predict_flower_type(filenames):\n",
    "    result = old_fn(filenames) # has flower_type_int etc.\n",
    "    result['filename'] = filenames\n",
    "    return result\n",
    "\n",
    "shutil.rmtree('export', ignore_errors=True)\n",
    "os.mkdir('export')\n",
    "model.save('export/flowers_model',\n",
    "          signatures={\n",
    "              'serving_default': predict_flower_type\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:28:01.865116: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 21:28:01.865166: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['filenames'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_filenames:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['filename'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "  outputs['flower_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:1\n",
      "  outputs['flower_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:2\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:3\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --signature_def serving_default --dir export/flowers_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
      "array([0.61915255, 0.9999844 , 0.99508286, 0.9751858 , 0.954917  ],\n",
      "      dtype=float32)>, 'flower_type_str': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'dandelion', b'dandelion', b'daisy', b'tulips', b'tulips'],\n",
      "      dtype=object)>, 'filename': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
      "array([b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
      "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n",
      "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n",
      "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n",
      "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'],\n",
      "      dtype=object)>, 'flower_type_int': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 1, 0, 4, 4])>}\n"
     ]
    }
   ],
   "source": [
    "serving_fn = tf.keras.models.load_model('export/flowers_model').signatures['serving_default']\n",
    "filenames = [\n",
    "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
    "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n",
    "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n",
    "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n",
    "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'\n",
    "]\n",
    "pred = serving_fn(tf.convert_to_tensor(filenames))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数のSignature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/flowers_model2/assets\n"
     ]
    }
   ],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
    "def pass_through_input(filenames):\n",
    "    result = old_fn(filenames) # has flower_type_int etc.\n",
    "    result['filename'] = filenames\n",
    "    return result\n",
    "\n",
    "shutil.rmtree('export', ignore_errors=True)\n",
    "os.mkdir('export')\n",
    "model.save('export/flowers_model2',\n",
    "          signatures={\n",
    "              'serving_default': old_fn,\n",
    "              'input_pass_through': pass_through_input\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:28:17.227397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 21:28:17.227450: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
      "SignatureDef key: \"__saved_model_init_op\"\n",
      "SignatureDef key: \"input_pass_through\"\n",
      "SignatureDef key: \"serving_default\"\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --dir export/flowers_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:28:20.193490: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 21:28:20.193548: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['filenames'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_filenames:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['flower_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:0\n",
      "  outputs['flower_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:1\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:2\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --dir export/flowers_model2 --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-17 21:28:23.166491: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 21:28:23.166543: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['filenames'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: input_pass_through_filenames:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['filename'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "  outputs['flower_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:1\n",
      "  outputs['flower_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:2\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:3\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --tag_set serve --dir export/flowers_model2 --signature_def input_pass_through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数のSignatureを持つモデルをREST APIとしてデプロイ\n",
    "以下のバケット名を変更してから実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['BUCKET'] = 'BUCKET' # CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://./export/flowers_model2/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./export/flowers_model2/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./export/flowers_model2/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./export/flowers_model2/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "/ [4/4 files][ 11.0 MiB/ 11.0 MiB] 100% Done                                    \n",
      "Operation completed over 4 objects/11.0 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil -m cp -r ./export/flowers_model2 gs://${BUCKET}/flowers_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルをデプロイします。この処理には10分ほど時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model multi\n",
      "The endpoint named multi already exists.\n",
      "The endpoint_id is 7785553875351633920\n",
      "The model named multi already exists.\n",
      "The model_id is 6103305482900865024\n",
      "Deploying model now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [1042486075676688384]...\n",
      ".............................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Deployed a model to the endpoint 7785553875351633920. Id of the deployed model: 4075691692072632320.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./vertex_deploy.sh \\\n",
    "--endpoint_name=multi \\\n",
    "--model_name=multi \\\n",
    "--model_location=gs://${BUCKET}/flowers_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要: 以下のセルを変更する\n",
    "上記のコマンドから出力された`endpoint_id`を下記にコピーしてください。<br>\n",
    "また、Google Cloudのプロジェクト名も正しく変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE TO REFLECT WHERE YOU DEPLOYED THE MODEL\n",
    "os.environ['ENDPOINT_ID'] = '7785553875351633920' # CHANGE\n",
    "os.environ['PROJECT'] = 'PROJECT' # CHANGE\n",
    "os.environ['REGION'] = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting request.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile request.json\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"deployedModelId\": \"4075691692072632320\",\n",
      "  \"model\": \"projects/849204435784/locations/us-central1/models/6103305482900865024\",\n",
      "  \"modelDisplayName\": \"multi\",\n",
      "  \"predictions\": [\n",
      "    {\n",
      "      \"flower_type_int\": 1,\n",
      "      \"flower_type_str\": \"dandelion\",\n",
      "      \"probability\": 0.619152546\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 1,\n",
      "      \"flower_type_str\": \"dandelion\",\n",
      "      \"probability\": 0.999984384\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 0,\n",
      "      \"flower_type_str\": \"daisy\",\n",
      "      \"probability\": 0.995082855\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 4,\n",
      "      \"flower_type_str\": \"tulips\",\n",
      "      \"probability\": 0.975185812\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 4,\n",
      "      \"flower_type_str\": \"tulips\",\n",
      "      \"probability\": 0.954917\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai endpoints predict ${ENDPOINT_ID} \\\n",
    "--region=${REGION} \\\n",
    "--json-request=request.json \\\n",
    "--format=json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting request.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile request.json\n",
    "{\n",
    "    \"signature_name\": \"input_pass_through\",\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在Vertex AIでは、`gcloud ai endpoints predict`ではなく、`gcloud ai endpoints raw-predict`コマンドで`signature_name`キーをサポートしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [\n",
      "        {\n",
      "            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\",\n",
      "            \"flower_type_str\": \"dandelion\",\n",
      "            \"probability\": 0.619152546,\n",
      "            \"flower_type_int\": 1\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\",\n",
      "            \"flower_type_str\": \"dandelion\",\n",
      "            \"probability\": 0.999984384,\n",
      "            \"flower_type_int\": 1\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\",\n",
      "            \"flower_type_str\": \"daisy\",\n",
      "            \"probability\": 0.995082855,\n",
      "            \"flower_type_int\": 0\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\",\n",
      "            \"flower_type_str\": \"tulips\",\n",
      "            \"probability\": 0.975185812,\n",
      "            \"flower_type_int\": 4\n",
      "        },\n",
      "        {\n",
      "            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\",\n",
      "            \"flower_type_str\": \"tulips\",\n",
      "            \"probability\": 0.954917,\n",
      "            \"flower_type_int\": 4\n",
      "        }\n",
      "    ]\n",
      "}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai endpoints raw-predict ${ENDPOINT_ID} \\\n",
    "--region=${REGION} \\\n",
    "--request=@request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n    \"predictions\": [\\n        {\\n            \"flower_type_str\": \"dandelion\",\\n            \"probability\": 0.619152546,\\n            \"flower_type_int\": 1,\\n            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\\n        },\\n        {\\n            \"flower_type_str\": \"dandelion\",\\n            \"probability\": 0.999984384,\\n            \"flower_type_int\": 1,\\n            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\\n        },\\n        {\\n            \"flower_type_str\": \"daisy\",\\n            \"probability\": 0.995082855,\\n            \"flower_type_int\": 0,\\n            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\\n        },\\n        {\\n            \"flower_type_str\": \"tulips\",\\n            \"probability\": 0.975185812,\\n            \"flower_type_int\": 4,\\n            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\\n        },\\n        {\\n            \"flower_type_str\": \"tulips\",\\n            \"probability\": 0.954917,\\n            \"flower_type_int\": 4,\\n            \"filename\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\\n        }\\n    ]\\n}'\n"
     ]
    }
   ],
   "source": [
    "# Invoke from Python.\n",
    "import json\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "\n",
    "PROJECT = os.environ['PROJECT']\n",
    "REGION = os.environ['REGION']\n",
    "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:rawPredict\".format(\n",
    "    REGION, PROJECT, REGION, ENDPOINT_ID)\n",
    "headers = {\"Authorization\": \"Bearer \" + token }\n",
    "data = {\n",
    "    \"signature_name\": \"input_pass_through\",\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duu8mX3iXANE"
   },
   "source": [
    "## License\n",
    "Copyright 2022 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
