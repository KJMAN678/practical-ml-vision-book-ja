{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 72}, "id": "hiQ6zAoYhyaA", "outputId": "0acee878-1207-42c3-9bee-a594acd44365"}, "outputs": [{"data": {"text/markdown": ["\n", "<table class=\"tfo-notebook-buttons\" align=\"left\">\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=Changing signatures of exported model&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F09_deploying%2F09c_changesig.ipynb&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F09_deploying%2F09c_changesig.ipynb\">\n", "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n", "  </td>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09c_changesig.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09c_changesig.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n", "  </td>\n", "  <td>\n", "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/09_deploying/09c_changesig.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n", "  </td>\n", "</table>\n"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["from IPython.display import Markdown as md\n", "\n", "### change to reflect your notebook\n", "_nb_loc = \"09_deploying/09c_changesig.ipynb\"\n", "_nb_title = \"Changing signatures of exported model\"\n", "\n", "### no need to change any of this\n", "_nb_safeloc = _nb_loc.replace('/', '%2F')\n", "md(\"\"\"\n", "<table class=\"tfo-notebook-buttons\" align=\"left\">\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name={1}&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F{2}&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F{2}\">\n", "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n", "  </td>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n", "  </td>\n", "  <td>\n", "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n", "  </td>\n", "</table>\n", "\"\"\".format(_nb_loc, _nb_title, _nb_safeloc))"]}, {"cell_type": "markdown", "metadata": {"id": "a8HQYsAtC0Fv"}, "source": ["# \u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3055\u308c\u305f\u30e2\u30c7\u30eb\u306e\u7f72\u540d\u306e\u5909\u66f4  \n", "\n", "\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001(\u7b2c7\u7ae0\u306e\u3088\u3046\u306b)\u3059\u3067\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u304b\u3089\u59cb\u3081\u307e\u3059\u3002  \n", "\u4fbf\u5b9c\u4e0a\u3001\u3053\u306e\u30e2\u30c7\u30eb\u3092gs\uff1a//practical-ml-vision-book/flowers_5_trained\u306e\u30d1\u30d6\u30ea\u30c3\u30af\u30d0\u30b1\u30c3\u30c8\u306b\u914d\u7f6e\u3057\u307e\u3057\u305f"]}, {"cell_type": "markdown", "metadata": {"id": "5UOm2etrwYCs"}, "source": ["## GPU\u3092\u6709\u52b9\u306b\u3057\u3001\u30d8\u30eb\u30d1\u30fc\u95a2\u6570\u3092\u8a2d\u5b9a\u3057\u307e\u3059  \n", "\n", "\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3068\u3001\u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u5185\u306e\u4ed6\u306e\u307b\u3068\u3093\u3069\u3059\u3079\u3066\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af  \n", "GPU\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u3088\u308a\u9ad8\u901f\u306b\u5b9f\u884c\u3055\u308c\u307e\u3059\u3002  \n", "Colab\u306b\u3064\u3044\u3066\uff1a  \n", "- [\u7de8\u96c6]\u2192[\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u8a2d\u5b9a]\u306b\u79fb\u52d5\u3057\u307e\u3059  \n", "- [\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u30a2\u30af\u30bb\u30e9\u30ec\u30fc\u30bf]\u30c9\u30ed\u30c3\u30d7\u30c0\u30a6\u30f3\u304b\u3089[GPU]\u3092\u9078\u629e\u3057\u307e\u3059  \n", "\n", "\u30af\u30e9\u30a6\u30c9AI\u30d7\u30e9\u30c3\u30c8\u30d5\u30a9\u30fc\u30e0\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\uff1a  \n", "- https://console.cloud.google.com/ai-platform/notebooks\u306b\u79fb\u52d5\u3057\u307e\u3059  \n", "- GPU\u3092\u4f7f\u7528\u3057\u3066\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u4f5c\u6210\u3059\u308b\u304b\u3001\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u9078\u629e\u3057\u3066GPU\u3092\u8ffd\u52a0\u3057\u307e\u3059  \n", "\n", "\u6b21\u306b\u3001\u30c6\u30f3\u30bd\u30eb\u30d5\u30ed\u30fc\u3092\u4f7f\u7528\u3057\u3066GPU\u306b\u63a5\u7d9a\u3067\u304d\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ugGJcxKAwhc2", "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["TensorFlow version2.6.2\n", "Built with GPU support? Yes!\n", "There are 1 GPUs\n", "Found GPU at: /device:GPU:0\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2021-12-05 02:36:35.367935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.376968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.377557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.378801: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n", "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n", "2021-12-05 02:36:35.379587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.380207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.380747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.851798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.852532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.853109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:35.853696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"]}], "source": ["import tensorflow as tf\n", "print('TensorFlow version' + tf.version.VERSION)\n", "print('Built with GPU support? ' + ('Yes!' if tf.test.is_built_with_cuda() else 'Noooo!'))\n", "print('There are {} GPUs'.format(len(tf.config.experimental.list_physical_devices(\"GPU\"))))\n", "device_name = tf.test.gpu_device_name()\n", "if device_name != '/device:GPU:0':\n", "    raise SystemError('GPU device not found')\n", "print('Found GPU at: {}'.format(device_name))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3055\u308c\u305f\u30e2\u30c7\u30eb  \n", "\n", "\u7b2c7\u7ae0\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u304a\u3088\u3073\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u304b\u3089\u59cb\u3081\u307e\u3059\u3002  \n", "```\n", "  model.save(...)\n", "```"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["MODEL_LOCATION='gs://practical-ml-vision-book/flowers_5_trained'"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["gs://practical-ml-vision-book/flowers_5_trained/saved_model.pb\n", "gs://practical-ml-vision-book/flowers_5_trained/chkpts/\n", "gs://practical-ml-vision-book/flowers_5_trained/variables/\n"]}], "source": ["!gsutil ls {MODEL_LOCATION}"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel SignatureDef contains the following input(s):\n", "  inputs['filenames'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: serving_default_filenames:0\n", "The given SavedModel SignatureDef contains the following output(s):\n", "  outputs['flower_type_int'] tensor_info:\n", "      dtype: DT_INT64\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:0\n", "  outputs['flower_type_str'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:1\n", "  outputs['probability'] tensor_info:\n", "      dtype: DT_FLOAT\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:2\n", "Method name is: tensorflow/serving/predict\n"]}], "source": ["!saved_model_cli show --tag_set serve --signature_def serving_default --dir {MODEL_LOCATION}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u5165\u529b\u3092\u901a\u904e\u3059\u308b  \n", "\n", "\u7f72\u540d\u306f\u5165\u529b\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u6559\u3048\u3066\u304f\u308c\u306a\u3044\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002  \n", "\u305d\u308c\u3092\u8ffd\u52a0\u3057\u307e\u3057\u3087\u3046\u3002"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2021-12-05 02:36:42.073546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:42.074258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:42.074816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:42.075456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:42.076125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n", "2021-12-05 02:36:42.076667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n", "2021-12-05 02:37:00.706013: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n", "2021-12-05 02:37:00.717402: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Assets written to: export/flowers_model/assets\n"]}], "source": ["import os\n", "import shutil\n", "import tensorflow as tf\n", "model = tf.keras.models.load_model(MODEL_LOCATION)\n", "\n", "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n", "def predict_flower_type(filenames):\n", "    old_fn = model.signatures['serving_default']\n", "    result = old_fn(filenames) # has flower_type_int etc.\n", "    result['filename'] = filenames\n", "    return result\n", "\n", "shutil.rmtree('export', ignore_errors=True)\n", "os.mkdir('export')\n", "model.save('export/flowers_model',\n", "          signatures={\n", "              'serving_default': predict_flower_type\n", "          })"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel SignatureDef contains the following input(s):\n", "  inputs['filenames'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: serving_default_filenames:0\n", "The given SavedModel SignatureDef contains the following output(s):\n", "  outputs['filename'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:0\n", "  outputs['flower_type_int'] tensor_info:\n", "      dtype: DT_INT64\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:1\n", "  outputs['flower_type_str'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:2\n", "  outputs['probability'] tensor_info:\n", "      dtype: DT_FLOAT\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:3\n", "Method name is: tensorflow/serving/predict\n"]}], "source": ["!saved_model_cli show --tag_set serve --signature_def serving_default --dir export/flowers_model"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["2021-12-05 02:37:09.518516: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]}, {"name": "stdout", "output_type": "stream", "text": ["{'flower_type_str': <tf.Tensor: shape=(5,), dtype=string, numpy=\n", "array([b'dandelion', b'dandelion', b'daisy', b'tulips', b'tulips'],\n", "      dtype=object)>, 'filename': <tf.Tensor: shape=(5,), dtype=string, numpy=\n", "array([b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n", "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n", "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n", "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n", "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'],\n", "      dtype=object)>, 'probability': <tf.Tensor: shape=(5,), dtype=float32, numpy=\n", "array([0.6191508 , 0.99998426, 0.99508286, 0.97518593, 0.9549181 ],\n", "      dtype=float32)>, 'flower_type_int': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 1, 0, 4, 4])>}\n"]}], "source": ["import tensorflow as tf\n", "serving_fn = tf.keras.models.load_model('export/flowers_model').signatures['serving_default']\n", "filenames = [\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n", "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'\n", "]\n", "pred = serving_fn(tf.convert_to_tensor(filenames))\n", "print(pred)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u8907\u6570\u306e\u7f72\u540d  \n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n", "INFO:tensorflow:Assets written to: export/flowers_model2/assets\n"]}], "source": ["import os\n", "import shutil\n", "import tensorflow as tf\n", "model = tf.keras.models.load_model(MODEL_LOCATION)\n", "old_fn = model.signatures['serving_default']\n", "\n", "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n", "def pass_through_input(filenames):\n", "    result = old_fn(filenames) # has flower_type_int etc.\n", "    result['filename'] = filenames\n", "    return result\n", "\n", "shutil.rmtree('export', ignore_errors=True)\n", "os.mkdir('export')\n", "model.save('export/flowers_model2',\n", "          signatures={\n", "              'serving_default': old_fn,\n", "              'input_pass_through': pass_through_input\n", "          })"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n", "SignatureDef key: \"__saved_model_init_op\"\n", "SignatureDef key: \"input_pass_through\"\n", "SignatureDef key: \"serving_default\"\n"]}], "source": ["!saved_model_cli show --tag_set serve --dir export/flowers_model2"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel SignatureDef contains the following input(s):\n", "  inputs['filenames'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: serving_default_filenames:0\n", "The given SavedModel SignatureDef contains the following output(s):\n", "  outputs['flower_type_int'] tensor_info:\n", "      dtype: DT_INT64\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall_1:0\n", "  outputs['flower_type_str'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall_1:1\n", "  outputs['probability'] tensor_info:\n", "      dtype: DT_FLOAT\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall_1:2\n", "Method name is: tensorflow/serving/predict\n"]}], "source": ["!saved_model_cli show --tag_set serve --dir export/flowers_model2 --signature_def serving_default"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The given SavedModel SignatureDef contains the following input(s):\n", "  inputs['filenames'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: input_pass_through_filenames:0\n", "The given SavedModel SignatureDef contains the following output(s):\n", "  outputs['filename'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:0\n", "  outputs['flower_type_int'] tensor_info:\n", "      dtype: DT_INT64\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:1\n", "  outputs['flower_type_str'] tensor_info:\n", "      dtype: DT_STRING\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:2\n", "  outputs['probability'] tensor_info:\n", "      dtype: DT_FLOAT\n", "      shape: (-1)\n", "      name: StatefulPartitionedCall:3\n", "Method name is: tensorflow/serving/predict\n"]}], "source": ["!saved_model_cli show --tag_set serve --dir export/flowers_model2 --signature_def input_pass_through"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u30de\u30eb\u30c1\u30b7\u30b0\u30cb\u30c1\u30e3\u30e2\u30c7\u30eb\u3092RESTAPI\u3068\u3057\u3066\u30c7\u30d7\u30ed\u30a4\u3059\u308b"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["Copying file://./export/flowers_model2/keras_metadata.pb [Content-Type=application/octet-stream]...\n", "Copying file://./export/flowers_model2/variables/variables.index [Content-Type=application/octet-stream]...\n", "Copying file://./export/flowers_model2/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n", "Copying file://./export/flowers_model2/saved_model.pb [Content-Type=application/octet-stream]...\n", "/ [4/4 files][ 10.9 MiB/ 10.9 MiB] 100% Done                                    \n", "Operation completed over 4 objects/10.9 MiB.                                     \n"]}], "source": ["%%bash\n", "BUCKET=\"ai-analytics-solutions-mlvisionbook\" # CHANGE\n", "gsutil -m cp -r ./export/flowers_model2 gs://${BUCKET}/flowers_model2"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Deploying model multi\n", "Creating multi endpoint now.\n", "The endpoint_id is 130472447798411264\n", "Uploading multi model now.\n", "The model_id is 8769849878676242432\n", "Deploying model now\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [1944520467301793792]...\n", "......done.\n", "Created Vertex AI endpoint: projects/379218021631/locations/us-central1/endpoints/130472447798411264.\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [6376062500634361856]...\n", "......................done.\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [2946571384391729152]...\n", "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n", "Deployed a model to the endpoint 130472447798411264. Id of the deployed model: 1810350293179695104.\n"]}], "source": ["%%bash\n", "BUCKET=\"ai-analytics-solutions-mlvisionbook\" # CHANGE\n", "./vertex_deploy.sh \\\n", "--endpoint_name=multi \\\n", "--model_name=multi \\\n", "--model_location=gs://${BUCKET}/flowers_model2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u91cd\u8981\uff1a\u3053\u306e\u30bb\u30eb\u3092\u5909\u66f4\u3059\u308b  \n", "\n", "\u4e0a\u8a18\u306e\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8ID\u3068\u30c7\u30d7\u30ed\u30a4\u3055\u308c\u305f\u30e2\u30c7\u30ebID\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u4e0b\u306e\u30bb\u30eb\u306b\u8a2d\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [], "source": ["# CHANGE THESE TO REFLECT WHERE YOU DEPLOYED THE MODEL\n", "import os\n", "os.environ['ENDPOINT_ID'] = '130472447798411264' # CHANGE\n", "os.environ['MODEL_ID'] = '1810350293179695104' # CHANGE\n", "os.environ['PROJECT'] = 'ai-analytics-solutions' # CHANGE\n", "os.environ['BUCKET'] = 'ai-analytics-solutions-mlvisionbook' # CHANGE\n", "os.environ['REGION'] = 'us-central1' # CHANGE"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Overwriting request.json\n"]}], "source": ["%%writefile request.json\n", "{\n", "    \"instances\": [\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n", "        }\n", "    ]\n", "}"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "  \"deployedModelId\": \"1810350293179695104\",\n", "  \"model\": \"projects/379218021631/locations/us-central1/models/8769849878676242432\",\n", "  \"modelDisplayName\": \"multi\",\n", "  \"predictions\": [\n", "    {\n", "      \"flower_type_int\": 1,\n", "      \"flower_type_str\": \"dandelion\",\n", "      \"probability\": 0.619152546\n", "    },\n", "    {\n", "      \"flower_type_int\": 1,\n", "      \"flower_type_str\": \"dandelion\",\n", "      \"probability\": 0.999984384\n", "    },\n", "    {\n", "      \"flower_type_int\": 0,\n", "      \"flower_type_str\": \"daisy\",\n", "      \"probability\": 0.995082855\n", "    },\n", "    {\n", "      \"flower_type_int\": 4,\n", "      \"flower_type_str\": \"tulips\",\n", "      \"probability\": 0.975185812\n", "    },\n", "    {\n", "      \"flower_type_int\": 4,\n", "      \"flower_type_str\": \"tulips\",\n", "      \"probability\": 0.954917\n", "    }\n", "  ]\n", "}\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"]}], "source": ["%%bash\n", "gcloud ai endpoints predict ${ENDPOINT_ID} \\\n", "--region=${REGION} \\\n", "--json-request=request.json \\\n", "--format=json"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Overwriting request.json\n"]}], "source": ["%%writefile request.json\n", "{\n", "    \"signature_name\": \"input_pass_through\",\n", "    \"instances\": [\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n", "        }\n", "    ]\n", "}"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "  \"deployedModelId\": \"1810350293179695104\",\n", "  \"model\": \"projects/379218021631/locations/us-central1/models/8769849878676242432\",\n", "  \"modelDisplayName\": \"multi\",\n", "  \"predictions\": [\n", "    {\n", "      \"flower_type_int\": 1,\n", "      \"flower_type_str\": \"dandelion\",\n", "      \"probability\": 0.619152546\n", "    },\n", "    {\n", "      \"flower_type_int\": 1,\n", "      \"flower_type_str\": \"dandelion\",\n", "      \"probability\": 0.999984384\n", "    },\n", "    {\n", "      \"flower_type_int\": 0,\n", "      \"flower_type_str\": \"daisy\",\n", "      \"probability\": 0.995082855\n", "    },\n", "    {\n", "      \"flower_type_int\": 4,\n", "      \"flower_type_str\": \"tulips\",\n", "      \"probability\": 0.975185812\n", "    },\n", "    {\n", "      \"flower_type_int\": 4,\n", "      \"flower_type_str\": \"tulips\",\n", "      \"probability\": 0.954917\n", "    }\n", "  ]\n", "}\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"]}], "source": ["%%bash\n", "gcloud ai endpoints predict ${ENDPOINT_ID} \\\n", "--region=${REGION} \\\n", "--json-request=request.json \\\n", "--format=json"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u3053\u308c\u306f\u30d0\u30b0\u3067\u3059\u3002\u30d0\u30b0\u30ec\u30dd\u30fc\u30c8\u3092\u63d0\u51fa\u3057\u307e\u3057\u305f\u3002\u3046\u307e\u304f\u3044\u3051\u3070\u3001\u3059\u3050\u306b\u4fee\u6b63\u3055\u308c\u307e\u3059\u3002"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b'{\\n  \"error\": {\\n    \"code\": 400,\\n    \"message\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\",\\n    \"status\": \"INVALID_ARGUMENT\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\\n        \"fieldViolations\": [\\n          {\\n            \"description\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\"\\n          }\\n        ]\\n      }\\n    ]\\n  }\\n}\\n'\n"]}], "source": ["# Invoke from Python.\n", "import json\n", "from oauth2client.client import GoogleCredentials\n", "import requests\n", "\n", "PROJECT = os.environ['PROJECT']\n", "REGION = os.environ['REGION']\n", "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n", "\n", "token = GoogleCredentials.get_application_default().get_access_token().access_token\n", "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n", "    REGION, PROJECT, REGION, ENDPOINT_ID)\n", "headers = {\"Authorization\": \"Bearer \" + token }\n", "data = {\n", "    \"signature_name\": \"input_pass_through\",  # currently bugged\n", "    \"instances\": [\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n", "        }\n", "    ]\n", "}\n", "response = requests.post(api, json=data, headers=headers)\n", "print(response.content)"]}, {"cell_type": "markdown", "metadata": {"id": "Duu8mX3iXANE"}, "source": ["## \u30e9\u30a4\u30bb\u30f3\u30b9  \n", "Copyright 2020 Google Inc. Apache License\u30d0\u30fc\u30b8\u30e7\u30f32.0(\u300c\u30e9\u30a4\u30bb\u30f3\u30b9\u300d)\u306b\u57fa\u3065\u3044\u3066\u30e9\u30a4\u30bb\u30f3\u30b9\u4f9b\u4e0e\u3055\u308c\u307e\u3059\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u6e96\u62e0\u3059\u308b\u5834\u5408\u3092\u9664\u304d\u3001\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u30b3\u30d4\u30fc\u306fhttp://www.apache.org/licenses/LICENSE-2.0\u3067\u5165\u624b\u3067\u304d\u307e\u3059\u3002\u9069\u7528\u6cd5\u3067\u8981\u6c42\u3055\u308c\u3066\u3044\u308b\u304b\u3001\u66f8\u9762\u3067\u5408\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u9650\u308a\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u3044\u3066\u914d\u5e03\u3055\u308c\u308b\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306f\u300c\u73fe\u72b6\u6709\u59ff\u300d\u3067\u914d\u5e03\u3055\u308c\u307e\u3059\u3002\u660e\u793a\u307e\u305f\u306f\u9ed9\u793a\u3092\u554f\u308f\u305a\u3001\u3044\u304b\u306a\u308b\u7a2e\u985e\u306e\u4fdd\u8a3c\u307e\u305f\u306f\u6761\u4ef6\u3082\u3042\u308a\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u304f\u8a31\u53ef\u3068\u5236\u9650\u3092\u898f\u5b9a\u3059\u308b\u7279\u5b9a\u306e\u8a00\u8a9e\u306b\u3064\u3044\u3066\u306f\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": ["5UOm2etrwYCs"], "name": "03a_transfer_learning.ipynb", "provenance": [], "toc_visible": true}, "environment": {"kernel": "python3", "name": "tf2-gpu.2-8.m90", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m90"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 4}