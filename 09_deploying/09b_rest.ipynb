{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 72}, "id": "hiQ6zAoYhyaA", "outputId": "0acee878-1207-42c3-9bee-a594acd44365"}, "outputs": [{"data": {"text/markdown": ["\n", "<table class=\"tfo-notebook-buttons\" align=\"left\">\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=Predictions using a REST endpoint&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F09_deploying%2F09b_rest.ipynb&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F09_deploying%2F09b_rest.ipynb\">\n", "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n", "  </td>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09b_rest.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/09_deploying/09b_rest.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n", "  </td>\n", "  <td>\n", "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/09_deploying/09b_rest.ipynb\">\n", "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n", "  </td>\n", "</table>\n"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["from IPython.display import Markdown as md\n", "\n", "### change to reflect your notebook\n", "_nb_loc = \"09_deploying/09b_rest.ipynb\"\n", "_nb_title = \"Predictions using a REST endpoint\"\n", "\n", "### no need to change any of this\n", "_nb_safeloc = _nb_loc.replace(\"/\", \"%2F\")\n", "md(\"\"\"\n", "<table class=\"tfo-notebook-buttons\" align=\"left\">\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name={1}&url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fblob%2Fmaster%2F{2}&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F{2}\">\n", "    <img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/> Run in AI Platform Notebook</a>\n", "  </td>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n", "  </td>\n", "  <td>\n", "    <a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n", "  </td>\n", "  <td>\n", "    <a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/{0}\">\n", "    <img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n", "  </td>\n", "</table>\n", "\"\"\".format(_nb_loc, _nb_title, _nb_safeloc))"]}, {"cell_type": "markdown", "metadata": {"id": "a8HQYsAtC0Fv"}, "source": ["# REST\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u3092\u4f7f\u7528\u3057\u305f\u4e88\u6e2c  \n", "\n", "\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001(\u7b2c7\u7ae0\u306e\u3088\u3046\u306b)\u3059\u3067\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u304b\u3089\u59cb\u3081\u307e\u3059\u3002  \n", "\u4fbf\u5b9c\u4e0a\u3001\u3053\u306e\u30e2\u30c7\u30eb\u3092gs\uff1a//practical-ml-vision-book/flowers_5_trained\u306e\u30d1\u30d6\u30ea\u30c3\u30af\u30d0\u30b1\u30c3\u30c8\u306b\u914d\u7f6e\u3057\u307e\u3057\u305f  \n", "\n", "\u3053\u306e\u30e2\u30c7\u30eb\u3092REST\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u306b\u30c7\u30d7\u30ed\u30a4\u3057\u3066\u304b\u3089\u3001POST\u64cd\u4f5c\u3092\u4f7f\u7528\u3057\u3066\u30e2\u30c7\u30eb\u3092\u547c\u3073\u51fa\u3059\u65b9\u6cd5\u3092\u793a\u3057\u307e\u3059\u3002"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## REST\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["#!/bin/bash\n", "\n", "REGION=\"us-central1\"  # make sure you have GPU/TPU quota in this region\n", "ENDPOINT_NAME=\"flowers_endpoint\"\n", "MODEL_NAME=\"flowers\"\n", "MODEL_LOCATION=\"gs://practical-ml-vision-book/flowers_5_trained\"\n", "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-1:latest\"\n", "\n", "for i in \"$@\"\n", "do\n", "case $i in\n", "        -r=*|--region=*) REGION=\"${i#*=}\"; shift ;;\n", "        -e=*|--endpoint_name=*) ENDPOINT_NAME=\"${i#*=}\"; shift ;;\n", "        -m=*|--model_name=*) MODEL_NAME=\"${i#*=}\"; shift ;;\n", "        -l=*|--model_location=*) MODEL_LOCATION=\"${i#*=}\"; shift ;;\n", "        -i=*|--image_uri=*) IMAGE_URI=\"${i#*=}\"; shift ;;\n", "        *) echo \"Unknown parameter passed: $1\"; exit 1 ;;\n", "esac\n", "done\n", "\n", "echo \"Deploying model $MODEL_NAME\"\n", "\n", "if [[ $(gcloud ai endpoints list --region=$REGION --format=\"value(display_name)\" | grep $ENDPOINT_NAME) ]]; then\n", "    echo \"The endpoint named $ENDPOINT_NAME already exists.\"\n", "else\n", "    # Create endpoint.\n", "    echo \"Creating $ENDPOINT_NAME endpoint now.\"\n", "    gcloud ai endpoints create \\\n", "      --region=$REGION \\\n", "      --display-name=$ENDPOINT_NAME\n", "fi\n", "\n", "ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$ENDPOINT_NAME\")\n", "echo \"The endpoint_id is $ENDPOINT_ID\"\n", "\n", "if [[ $(gcloud ai models list --region=$REGION --format=\"value(display_name)\" | grep $MODEL_NAME) ]]; then\n", "    echo \"The model named $MODEL_NAME already exists.\"\n", "else\n", "    # Upload model.\n", "    echo \"Uploading $MODEL_NAME model now.\"\n", "    gcloud ai models upload \\\n", "      --region=$REGION \\\n", "      --display-name=$MODEL_NAME \\\n", "      --container-image-uri=$IMAGE_URI \\\n", "      --artifact-uri=$MODEL_LOCATION\n", "fi\n", "\n", "MODEL_ID=$(gcloud ai models list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$MODEL_NAME\")\n", "echo \"The model_id is $MODEL_ID\"\n", "\n", "echo \"Deploying model now\"\n", "gcloud ai endpoints deploy-model $ENDPOINT_ID\\\n", "  --region=$REGION \\\n", "  --model=$MODEL_ID \\\n", "  --display-name=$MODEL_NAME \\\n", "  --traffic-split=0=100\n"]}], "source": ["!cat ./vertex_deploy.sh"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Deploying model flowers\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "The endpoint named flowers_endpoint already exists.\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "The endpoint_id is 4327589805996113920\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Uploading flowers model now.\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [8618855115064868864]...done.                            \n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "The model_id is 4626538221495386112\n", "Deploying model now\n", "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n", "Waiting for operation [3921600703717441536]...done.                            \n", "Deployed a model to the endpoint 4327589805996113920. Id of the deployed model: 1963683786742824960.\n"]}], "source": ["!./vertex_deploy.sh"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u91cd\u8981\uff1a\u3053\u306e\u30bb\u30eb\u3092\u5909\u66f4\u3059\u308b"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u4e0a\u8a18\u306e\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8ID\u3068\u30c7\u30d7\u30ed\u30a4\u3055\u308c\u305f\u30e2\u30c7\u30ebID\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u4e0b\u306e\u30bb\u30eb\u306b\u8a2d\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["# CHANGE THESE TO REFLECT WHERE YOU DEPLOYED THE MODEL\n", "import os\n", "os.environ['ENDPOINT_ID'] = '4327589805996113920' # CHANGE\n", "os.environ['MODEL_ID'] = '1963683786742824960' # CHANGE\n", "os.environ['PROJECT'] = 'ai-analytics-solutions' # CHANGE\n", "os.environ['BUCKET'] = 'ai-analytics-solutions-mlvisionbook' # CHANGE\n", "os.environ['REGION'] = 'us-central1' # CHANGE"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## JSON\u30ea\u30af\u30a8\u30b9\u30c8"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Writing request.json\n"]}], "source": ["%%writefile request.json\n", "{\n", "    \"instances\": [\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n", "        }\n", "    ]\n", "}"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "  \"deployedModelId\": \"1963683786742824960\",\n", "  \"model\": \"projects/379218021631/locations/us-central1/models/4626538221495386112\",\n", "  \"modelDisplayName\": \"flowers\",\n", "  \"predictions\": [\n", "    {\n", "      \"flower_type_int\": 1,\n", "      \"flower_type_str\": \"dandelion\",\n", "      \"probability\": 0.619152546\n", "    },\n", "    {\n", "      \"flower_type_int\": 1,\n", "      \"flower_type_str\": \"dandelion\",\n", "      \"probability\": 0.999984384\n", "    },\n", "    {\n", "      \"flower_type_int\": 0,\n", "      \"flower_type_str\": \"daisy\",\n", "      \"probability\": 0.995082855\n", "    },\n", "    {\n", "      \"flower_type_int\": 4,\n", "      \"flower_type_str\": \"tulips\",\n", "      \"probability\": 0.975185812\n", "    },\n", "    {\n", "      \"flower_type_int\": 4,\n", "      \"flower_type_str\": \"tulips\",\n", "      \"probability\": 0.954917\n", "    }\n", "  ]\n", "}\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"]}], "source": ["%%bash\n", "gcloud ai endpoints predict ${ENDPOINT_ID} \\\n", "--region=${REGION} \\\n", "--json-request=request.json \\\n", "--format=json"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## HTTPPost\u3092\u4ecb\u3057\u305f\u9001\u4fe1"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["b'{\\n  \"predictions\": [\\n    {\\n      \"flower_type_int\": 1,\\n      \"probability\": 0.619152546,\\n      \"flower_type_str\": \"dandelion\"\\n    },\\n    {\\n      \"flower_type_str\": \"dandelion\",\\n      \"probability\": 0.999984384,\\n      \"flower_type_int\": 1\\n    },\\n    {\\n      \"probability\": 0.995082855,\\n      \"flower_type_str\": \"daisy\",\\n      \"flower_type_int\": 0\\n    },\\n    {\\n      \"probability\": 0.975185812,\\n      \"flower_type_str\": \"tulips\",\\n      \"flower_type_int\": 4\\n    },\\n    {\\n      \"flower_type_int\": 4,\\n      \"flower_type_str\": \"tulips\",\\n      \"probability\": 0.954917\\n    }\\n  ],\\n  \"deployedModelId\": \"1963683786742824960\",\\n  \"model\": \"projects/379218021631/locations/us-central1/models/4626538221495386112\",\\n  \"modelDisplayName\": \"flowers\"\\n}\\n'\n"]}], "source": ["# Invoke from Python.\n", "import json\n", "from oauth2client.client import GoogleCredentials\n", "import requests\n", "\n", "PROJECT = os.environ['PROJECT']\n", "REGION = os.environ['REGION']\n", "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n", "\n", "token = GoogleCredentials.get_application_default().get_access_token().access_token\n", "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n", "    REGION, PROJECT, REGION, ENDPOINT_ID)\n", "headers = {\"Authorization\": \"Bearer \" + token }\n", "data = {\n", "    \"instances\": [\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n", "        },\n", "        {\n", "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n", "        }\n", "    ]\n", "}\n", "response = requests.post(api, json=data, headers=headers)\n", "print(response.content)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## [\u30aa\u30d7\u30b7\u30e7\u30f3] CAIP\u30d0\u30c3\u30c1\u4e88\u6e2c"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%writefile batchinputs.jsonl\n", "{\"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"}\n", "{\"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"}\n", "{\"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"}\n", "{\"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"}\n", "{\"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%bash\n", "gsutil cp batchinputs.jsonl gs://BUCKET"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Invoke from Python.\n", "import json\n", "from oauth2client.client import GoogleCredentials\n", "import requests\n", "\n", "PROJECT = os.environ['PROJECT']\n", "REGION = os.environ['REGION']\n", "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n", "MODEL_ID = os.environ['MODEL_ID']\n", "BUCKET = os.environ['BUCKET'] # used for staging\n", "\n", "BATCH_JOB_NAME = \"batch_pred_job\"\n", "INPUT_FORMAT = \"jsonl\"\n", "INPUT_URI = \"gs://{}/batchinputs.jsonl\".format(BUCKET)\n", "OUTPUT_DIRECTORY = \"gs://{}/batch_predictions\".format(BUCKET)\n", "MACHINE_TYPE = \"n1-standard-2\"\n", "STARTING_REPLICA_COUNT = 1\n", "BATCH_SIZE = 64\n", "\n", "token = GoogleCredentials.get_application_default().get_access_token().access_token\n", "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/batchPredictionJobs\".format(\n", "    REGION, PROJECT, REGION\n", ")\n", "headers = {\"Authorization\": \"Bearer \" + token}\n", "data = {\n", "    \"displayName\": BATCH_JOB_NAME,\n", "    \"model\": \"projects/{}/locations/{}/models/{}\".format(\n", "        PROJECT, REGION, MODEL_ID\n", "    ),\n", "    \"inputConfig\": {\n", "        \"instancesFormat\": INPUT_FORMAT,\n", "        \"gcsSource\": {\n", "            \"uris\": [INPUT_URI],\n", "        },\n", "    },\n", "    \"outputConfig\": {\n", "        \"predictionsFormat\": \"jsonl\",\n", "        \"gcsDestination\": {\n", "            \"outputUriPrefix\": OUTPUT_DIRECTORY,\n", "        },\n", "    },\n", "    \"dedicatedResources\" : {\n", "        \"machineSpec\" : {\n", "            \"machineType\": MACHINE_TYPE\n", "        },\n", "        \"startingReplicaCount\": STARTING_REPLICA_COUNT\n", "    },\n", "    \"manualBatchTuningParameters\": {\n", "        \"batch_size\": BATCH_SIZE,\n", "    }\n", "}\n", "response = requests.post(api, json=data, headers=headers)\n", "print(response.content)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## [\u30aa\u30d7\u30b7\u30e7\u30f3] ApacheBeam\u304b\u3089\u306e\u30aa\u30f3\u30e9\u30a4\u30f3\u4e88\u6e2c\u306e\u547c\u3073\u51fa\u3057"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import apache_beam as beam\n", "import json\n", "from oauth2client.client import GoogleCredentials\n", "import requests\n", "\n", "class ModelPredict:\n", "    def __init__(self, project, region, endpoint_id):\n", "        self._api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n", "            region, project, region, endpoint_id)   \n", "        \n", "    def __call__(self, filenames):        \n", "        token = GoogleCredentials.get_application_default().get_access_token().access_token\n", "        if isinstance(filenames, str):\n", "            # Only one element, put it into a batch of 1.\n", "            data = {\n", "                \"instances\": [\n", "                    {\"filenames\": filenames}\n", "                ]\n", "            }\n", "        else:\n", "            data = {\n", "                \"instances\": []\n", "            }\n", "            for f in filenames:\n", "                data[\"instances\"].append({\n", "                    \"filenames\" : f\n", "                })\n", "        # print(data)\n", "        headers = {\"Authorization\": \"Bearer \" + token }\n", "        response = requests.post(self._api, json=data, headers=headers)\n", "        response = json.loads(response.content.decode(\"utf-8\"))\n", "        # print(response)\n", "        if isinstance(filenames, str):\n", "            result = response[\"predictions\"][0]\n", "            result[\"filename\"] = filenames\n", "            yield result\n", "        else:\n", "            for (a,b) in zip(filenames, response[\"predictions\"]):\n", "                result = b\n", "                result[\"filename\"] = a\n", "                yield result\n", "\n", "\n", "PROJECT = os.environ['PROJECT']\n", "REGION = os.environ['REGION']\n", "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n", "\n", "with beam.Pipeline() as p:    \n", "    (p \n", "     | \"input\" >> beam.Create([\n", "        \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\",\n", "        \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\",\n", "        \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\",\n", "        \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\",\n", "        \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n", "     ]) \n", "     | \"batch\" >> beam.BatchElements(min_batch_size=2, max_batch_size=3)\n", "     | \"addpred\" >> beam.FlatMap(ModelPredict(PROJECT, REGION, ENDPOINT_ID))\n", "     | \"write\" >> beam.Map(print)\n", "    )"]}, {"cell_type": "markdown", "metadata": {"id": "Duu8mX3iXANE"}, "source": ["## \u30e9\u30a4\u30bb\u30f3\u30b9  \n", "Copyright 2020 Google Inc. Apache License\u30d0\u30fc\u30b8\u30e7\u30f32.0(\u300c\u30e9\u30a4\u30bb\u30f3\u30b9\u300d)\u306b\u57fa\u3065\u3044\u3066\u30e9\u30a4\u30bb\u30f3\u30b9\u4f9b\u4e0e\u3055\u308c\u307e\u3059\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u6e96\u62e0\u3059\u308b\u5834\u5408\u3092\u9664\u304d\u3001\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u30b3\u30d4\u30fc\u306fhttp://www.apache.org/licenses/LICENSE-2.0\u3067\u5165\u624b\u3067\u304d\u307e\u3059\u3002\u9069\u7528\u6cd5\u3067\u8981\u6c42\u3055\u308c\u3066\u3044\u308b\u304b\u3001\u66f8\u9762\u3067\u5408\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u9650\u308a\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u3044\u3066\u914d\u5e03\u3055\u308c\u308b\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306f\u300c\u73fe\u72b6\u6709\u59ff\u300d\u3067\u914d\u5e03\u3055\u308c\u307e\u3059\u3002\u660e\u793a\u307e\u305f\u306f\u9ed9\u793a\u3092\u554f\u308f\u305a\u3001\u3044\u304b\u306a\u308b\u7a2e\u985e\u306e\u4fdd\u8a3c\u307e\u305f\u306f\u6761\u4ef6\u3082\u3042\u308a\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u304f\u8a31\u53ef\u3068\u5236\u9650\u3092\u898f\u5b9a\u3059\u308b\u7279\u5b9a\u306e\u8a00\u8a9e\u306b\u3064\u3044\u3066\u306f\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}], "metadata": {"accelerator": "GPU", "colab": {"collapsed_sections": ["5UOm2etrwYCs"], "name": "03a_transfer_learning.ipynb", "provenance": [], "toc_visible": true}, "environment": {"kernel": "python3", "name": "tf2-gpu.2-6.m87", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 4}