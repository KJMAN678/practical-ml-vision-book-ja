{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "hiQ6zAoYhyaA",
    "outputId": "0acee878-1207-42c3-9bee-a594acd44365"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?name=Predictions+using+a+REST+endpoint&download_url=https%3A%2F%2Fgithub.com%2Ftakumiohym%2Fpractical-ml-vision-book-ja%2Fraw%2Fmaster%2F09_deploying%2F09b_rest.ipynb\"><img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/>Run in Vertex AI Workbench</a></td><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/takumiohym/practical-ml-vision-book-ja/blob/master/09_deploying/09b_rest.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"https://github.com/takumiohym/practical-ml-vision-book-ja/blob/master/09_deploying/09b_rest.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td><td><a href=\"https://raw.githubusercontent.com/takumiohym/practical-ml-vision-book-ja/master/09_deploying/09b_rest.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a></td></table><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmt: off\n",
    "import urllib\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "### change to reflect your notebook\n",
    "_nb_loc = \"09_deploying/09b_rest.ipynb\"\n",
    "_nb_title = \"Predictions using a REST endpoint\"\n",
    "\n",
    "_icons=[\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\", \"https://www.tensorflow.org/images/colab_logo_32px.png\", \"https://www.tensorflow.org/images/GitHub-Mark-32px.png\", \"https://www.tensorflow.org/images/download_logo_32px.png\"]\n",
    "_links=[\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?\" + urllib.parse.urlencode({\"name\": _nb_title, \"download_url\": \"https://github.com/takumiohym/practical-ml-vision-book-ja/raw/master/\"+_nb_loc}), \"https://colab.research.google.com/github/takumiohym/practical-ml-vision-book-ja/blob/master/{0}\".format(_nb_loc), \"https://github.com/takumiohym/practical-ml-vision-book-ja/blob/master/{0}\".format(_nb_loc), \"https://raw.githubusercontent.com/takumiohym/practical-ml-vision-book-ja/master/{0}\".format(_nb_loc)]\n",
    "md(\"\"\"<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"{0}\"><img src=\"{4}\"/>Run in Vertex AI Workbench</a></td><td><a target=\"_blank\" href=\"{1}\"><img src=\"{5}\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"{2}\"><img src=\"{6}\" />View source on GitHub</a></td><td><a href=\"{3}\"><img src=\"{7}\" />Download notebook</a></td></table><br/><br/>\"\"\".format(_links[0], _links[1], _links[2], _links[3], _icons[0], _icons[1], _icons[2], _icons[3]))\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8HQYsAtC0Fv"
   },
   "source": [
    "# RESTエンドポイントを使用した予測  \n",
    "\n",
    "このノートブックでは、学習済みでエクスポートされたモデルから始めます。  \n",
    "このモデルはパブリックの`gs://practical-ml-vision-book-data/flowers_5_trained`に保存されています。\n",
    "\n",
    "モデルをVeretx AIにデプロイし、様々な方法でモデルを呼び出す方法を示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境設定\n",
    "以下に使用するプロジェクト名を入力してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'PROJECT_NAME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colab環境を利用する場合、以下を実行して必要なモジュールのインストール、ファイルのダウンロード、プロジェクトの設定を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IS_COLAB_BACKEND = 'COLAB_RELEASE_TAG' in os.environ  # this is always set on Colab\n",
    "if IS_COLAB_BACKEND:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "\n",
    "    # Install dependencies\n",
    "    !pip install apache-beam==2.38.0\n",
    "\n",
    "    # Get files\n",
    "    BASE_PATH = \"https://raw.githubusercontent.com/takumiohym/practical-ml-vision-book-ja/main/09_deploying\"\n",
    "    !wget {BASE_PATH}/vertex_deploy.sh\n",
    "    !sudo chmod 755 ./vertex_deploy.sh\n",
    "\n",
    "    !gcloud config set project {PROJECT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Cloud Storageバケットの作成\n",
    "以下のBUCKETの値を使用可能なGSCバケット名に変更して進めてください。<br>\n",
    "使用できるバケットがない場合は、以下の二行目のコマンドをコメントアウトし、gsutil mbコマンドを実行して作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET='BUCKET_NAME' # Specify your GCS bucket name\n",
    "# !gsutil mb -l us-central1 -p {PROJECT} gs://{BUCKET} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESTエンドポイントの作成\n",
    "\n",
    "`vertex_deploy.sh` コマンドで、Vertex AIへ学習済みのモデルのアップロード（`gcloud ai models upload`）とデプロイ（`gcloud ai endpoints deploy-model`）を行います。\n",
    "\n",
    "実行には10分ほどの時間がかかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "REGION=\"us-central1\"  # make sure you have GPU/TPU quota in this region\n",
      "ENDPOINT_NAME=\"flowers_endpoint\"\n",
      "MODEL_NAME=\"flowers\"\n",
      "MODEL_LOCATION=\"gs://practical-ml-vision-book-data/flowers_5_trained\"\n",
      "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-4:latest\"\n",
      "\n",
      "for i in \"$@\"\n",
      "do\n",
      "case $i in\n",
      "        -r=*|--region=*) REGION=\"${i#*=}\"; shift ;;\n",
      "        -e=*|--endpoint_name=*) ENDPOINT_NAME=\"${i#*=}\"; shift ;;\n",
      "        -m=*|--model_name=*) MODEL_NAME=\"${i#*=}\"; shift ;;\n",
      "        -l=*|--model_location=*) MODEL_LOCATION=\"${i#*=}\"; shift ;;\n",
      "        -i=*|--image_uri=*) IMAGE_URI=\"${i#*=}\"; shift ;;\n",
      "        *) echo \"Unknown parameter passed: $1\"; exit 1 ;;\n",
      "esac\n",
      "done\n",
      "\n",
      "echo \"Deploying model $MODEL_NAME\"\n",
      "\n",
      "if [[ $(gcloud ai endpoints list --region=$REGION --format=\"value(display_name)\" | grep $ENDPOINT_NAME) ]]; then\n",
      "    echo \"The endpoint named $ENDPOINT_NAME already exists.\"\n",
      "else\n",
      "    # Create endpoint.\n",
      "    echo \"Creating $ENDPOINT_NAME endpoint now.\"\n",
      "    gcloud ai endpoints create \\\n",
      "      --region=$REGION \\\n",
      "      --display-name=$ENDPOINT_NAME\n",
      "fi\n",
      "\n",
      "ENDPOINT_ID=$(gcloud ai endpoints list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$ENDPOINT_NAME\")\n",
      "echo \"The endpoint_id is $ENDPOINT_ID\"\n",
      "\n",
      "if [[ $(gcloud ai models list --region=$REGION --format=\"value(display_name)\" | grep $MODEL_NAME) ]]; then\n",
      "    echo \"The model named $MODEL_NAME already exists.\"\n",
      "else\n",
      "    # Upload model.\n",
      "    echo \"Uploading $MODEL_NAME model now.\"\n",
      "    gcloud ai models upload \\\n",
      "      --region=$REGION \\\n",
      "      --display-name=$MODEL_NAME \\\n",
      "      --container-image-uri=$IMAGE_URI \\\n",
      "      --artifact-uri=$MODEL_LOCATION\n",
      "fi\n",
      "\n",
      "MODEL_ID=$(gcloud ai models list --region=$REGION --format=\"value(name)\" --filter=\"displayName=$MODEL_NAME\")\n",
      "echo \"The model_id is $MODEL_ID\"\n",
      "\n",
      "echo \"Deploying model now\"\n",
      "gcloud ai endpoints deploy-model $ENDPOINT_ID\\\n",
      "  --region=$REGION \\\n",
      "  --model=$MODEL_ID \\\n",
      "  --display-name=$MODEL_NAME \\\n",
      "  --traffic-split=0=100\n"
     ]
    }
   ],
   "source": [
    "!cat ./vertex_deploy.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model flowers\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Creating flowers_endpoint endpoint now.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [5503301506587164672]...done.                            \n",
      "Created Vertex AI endpoint: projects/849204435784/locations/us-central1/endpoints/7290157916340879360.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "The endpoint_id is 7290157916340879360\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Uploading flowers model now.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [3201962097000841216]...done.                            \n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "The model_id is 3925815063067230208\n",
      "Deploying model now\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [7809144515800858624]...done.                            \n",
      "Deployed a model to the endpoint 7290157916340879360. Id of the deployed model: 9036406681621233664.\n"
     ]
    }
   ],
   "source": [
    "!./vertex_deploy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以下のセルを変更する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のコマンドから出力された`endpoint_id`とデプロイされた`model_id`を下記にコピーしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE TO REFLECT WHERE YOU DEPLOYED THE MODEL\n",
    "import os\n",
    "os.environ['ENDPOINT_ID'] = '7290157916340879360' # CHANGE\n",
    "os.environ['MODEL_ID'] = '3925815063067230208' # CHANGE\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Prediction: gcloud コマンド\n",
    "Vertex AI Predictionを利用して、デプロイしたモデルにリクエストを送り、推論結果を取得します。\n",
    "\n",
    "モデルの入力に合わせて以下のjsonファイルを作成し、`gcloud ai endpoints predict`コマンドでリクエストを送ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting request.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile request.json\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"deployedModelId\": \"9036406681621233664\",\n",
      "  \"model\": \"projects/849204435784/locations/us-central1/models/3925815063067230208\",\n",
      "  \"modelDisplayName\": \"flowers\",\n",
      "  \"predictions\": [\n",
      "    {\n",
      "      \"flower_type_int\": 1,\n",
      "      \"flower_type_str\": \"dandelion\",\n",
      "      \"probability\": 0.619152546\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 1,\n",
      "      \"flower_type_str\": \"dandelion\",\n",
      "      \"probability\": 0.999984384\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 0,\n",
      "      \"flower_type_str\": \"daisy\",\n",
      "      \"probability\": 0.995082855\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 4,\n",
      "      \"flower_type_str\": \"tulips\",\n",
      "      \"probability\": 0.975185812\n",
      "    },\n",
      "    {\n",
      "      \"flower_type_int\": 4,\n",
      "      \"flower_type_str\": \"tulips\",\n",
      "      \"probability\": 0.954917\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai endpoints predict ${ENDPOINT_ID} \\\n",
    "--region=${REGION} \\\n",
    "--json-request=request.json \\\n",
    "--format=json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Prediction: HTTPリクエスト\n",
    "\n",
    "同様のことは、直接HTTPリクエストを定義して送信することでも行うことができます。（また、各プログラミング言語のGoogle Cloud SDKを使用することも可能です）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"predictions\": [\\n    {\\n      \"flower_type_int\": 1,\\n      \"probability\": 0.619152546,\\n      \"flower_type_str\": \"dandelion\"\\n    },\\n    {\\n      \"flower_type_int\": 1,\\n      \"flower_type_str\": \"dandelion\",\\n      \"probability\": 0.999984384\\n    },\\n    {\\n      \"flower_type_str\": \"daisy\",\\n      \"probability\": 0.995082855,\\n      \"flower_type_int\": 0\\n    },\\n    {\\n      \"flower_type_int\": 4,\\n      \"flower_type_str\": \"tulips\",\\n      \"probability\": 0.975185812\\n    },\\n    {\\n      \"flower_type_str\": \"tulips\",\\n      \"probability\": 0.954917,\\n      \"flower_type_int\": 4\\n    }\\n  ],\\n  \"deployedModelId\": \"9036406681621233664\",\\n  \"model\": \"projects/849204435784/locations/us-central1/models/3925815063067230208\",\\n  \"modelDisplayName\": \"flowers\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "# Invoke from Python.\n",
    "import json\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "\n",
    "PROJECT = os.environ['PROJECT']\n",
    "REGION = os.environ['REGION']\n",
    "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n",
    "    REGION, PROJECT, REGION, ENDPOINT_ID)\n",
    "headers = {\"Authorization\": \"Bearer \" + token }\n",
    "data = {\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
    "        },\n",
    "        {\n",
    "            \"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction\n",
    "続いて、Vertex AIを利用してバッチでの推論を行います。\n",
    "\n",
    "以下のようにJson Linesで入力データを定義し、送信します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batchinputs.jsonl\n"
     ]
    }
   ],
   "source": [
    "%%writefile batchinputs.jsonl\n",
    "{\"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"}\n",
    "{\"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"}\n",
    "{\"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"}\n",
    "{\"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"}\n",
    "{\"filenames\": \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://batchinputs.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  555.0 B/  555.0 B]                                                \n",
      "Operation completed over 1 objects/555.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cp batchinputs.jsonl gs://${BUCKET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"name\": \"projects/849204435784/locations/us-central1/batchPredictionJobs/8101512010610507776\",\\n  \"displayName\": \"batch_pred_job\",\\n  \"model\": \"projects/849204435784/locations/us-central1/models/3925815063067230208\",\\n  \"inputConfig\": {\\n    \"instancesFormat\": \"jsonl\",\\n    \"gcsSource\": {\\n      \"uris\": [\\n        \"gs://takumi-misc/batchinputs.jsonl\"\\n      ]\\n    }\\n  },\\n  \"outputConfig\": {\\n    \"predictionsFormat\": \"jsonl\",\\n    \"gcsDestination\": {\\n      \"outputUriPrefix\": \"gs://takumi-misc/batch_predictions\"\\n    }\\n  },\\n  \"dedicatedResources\": {\\n    \"machineSpec\": {\\n      \"machineType\": \"n1-standard-2\"\\n    },\\n    \"startingReplicaCount\": 1\\n  },\\n  \"manualBatchTuningParameters\": {\\n    \"batchSize\": 64\\n  },\\n  \"state\": \"JOB_STATE_PENDING\",\\n  \"createTime\": \"2022-07-17T21:27:20.654512Z\",\\n  \"updateTime\": \"2022-07-17T21:27:20.654512Z\",\\n  \"modelVersionId\": \"1\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "# Invoke from Python.\n",
    "import json\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "\n",
    "PROJECT = os.environ['PROJECT']\n",
    "REGION = os.environ['REGION']\n",
    "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n",
    "MODEL_ID = os.environ['MODEL_ID']\n",
    "BUCKET = os.environ['BUCKET'] # used for staging\n",
    "\n",
    "BATCH_JOB_NAME = \"batch_pred_job\"\n",
    "INPUT_FORMAT = \"jsonl\"\n",
    "INPUT_URI = \"gs://{}/batchinputs.jsonl\".format(BUCKET)\n",
    "OUTPUT_DIRECTORY = \"gs://{}/batch_predictions\".format(BUCKET)\n",
    "MACHINE_TYPE = \"n1-standard-2\"\n",
    "STARTING_REPLICA_COUNT = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/batchPredictionJobs\".format(\n",
    "    REGION, PROJECT, REGION\n",
    ")\n",
    "headers = {\"Authorization\": \"Bearer \" + token}\n",
    "data = {\n",
    "    \"displayName\": BATCH_JOB_NAME,\n",
    "    \"model\": \"projects/{}/locations/{}/models/{}\".format(\n",
    "        PROJECT, REGION, MODEL_ID\n",
    "    ),\n",
    "    \"inputConfig\": {\n",
    "        \"instancesFormat\": INPUT_FORMAT,\n",
    "        \"gcsSource\": {\n",
    "            \"uris\": [INPUT_URI],\n",
    "        },\n",
    "    },\n",
    "    \"outputConfig\": {\n",
    "        \"predictionsFormat\": \"jsonl\",\n",
    "        \"gcsDestination\": {\n",
    "            \"outputUriPrefix\": OUTPUT_DIRECTORY,\n",
    "        },\n",
    "    },\n",
    "    \"dedicatedResources\" : {\n",
    "        \"machineSpec\" : {\n",
    "            \"machineType\": MACHINE_TYPE\n",
    "        },\n",
    "        \"startingReplicaCount\": STARTING_REPLICA_COUNT\n",
    "    },\n",
    "    \"manualBatchTuningParameters\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "    }\n",
    "}\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache BeamからのOnline Predictionの呼び出し\n",
    "\n",
    "最後に、Vertex AIのOnline PredictionをApache Beamのパイプラインから呼び出す方法を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flower_type_str': 'dandelion', 'probability': 0.619152427, 'flower_type_int': 1, 'filename': 'gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg'}\n",
      "{'flower_type_int': 1, 'probability': 0.999984384, 'flower_type_str': 'dandelion', 'filename': 'gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg'}\n",
      "{'flower_type_str': 'daisy', 'flower_type_int': 0, 'probability': 0.995082855, 'filename': 'gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg'}\n",
      "{'flower_type_int': 4, 'flower_type_str': 'tulips', 'probability': 0.975185931, 'filename': 'gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg'}\n",
      "{'probability': 0.954917, 'flower_type_str': 'tulips', 'flower_type_int': 4, 'filename': 'gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'}\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import json\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import requests\n",
    "\n",
    "class ModelPredict:\n",
    "    def __init__(self, project, region, endpoint_id):\n",
    "        self._api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n",
    "            region, project, region, endpoint_id)   \n",
    "        \n",
    "    def __call__(self, filenames):        \n",
    "        token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
    "        if isinstance(filenames, str):\n",
    "            # Only one element, put it into a batch of 1.\n",
    "            data = {\n",
    "                \"instances\": [\n",
    "                    {\"filenames\": filenames}\n",
    "                ]\n",
    "            }\n",
    "        else:\n",
    "            data = {\n",
    "                \"instances\": []\n",
    "            }\n",
    "            for f in filenames:\n",
    "                data[\"instances\"].append({\n",
    "                    \"filenames\" : f\n",
    "                })\n",
    "        # print(data)\n",
    "        headers = {\"Authorization\": \"Bearer \" + token }\n",
    "        response = requests.post(self._api, json=data, headers=headers)\n",
    "        response = json.loads(response.content.decode(\"utf-8\"))\n",
    "        # print(response)\n",
    "        if isinstance(filenames, str):\n",
    "            result = response[\"predictions\"][0]\n",
    "            result[\"filename\"] = filenames\n",
    "            yield result\n",
    "        else:\n",
    "            for (a,b) in zip(filenames, response[\"predictions\"]):\n",
    "                result = b\n",
    "                result[\"filename\"] = a\n",
    "                yield result\n",
    "\n",
    "\n",
    "PROJECT = os.environ['PROJECT']\n",
    "REGION = os.environ['REGION']\n",
    "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n",
    "\n",
    "with beam.Pipeline() as p:    \n",
    "    (p \n",
    "     | \"input\" >> beam.Create([\n",
    "        \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\",\n",
    "        \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\",\n",
    "        \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\",\n",
    "        \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\",\n",
    "        \"gs://practical-ml-vision-book-data/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
    "     ]) \n",
    "     | \"batch\" >> beam.BatchElements(min_batch_size=2, max_batch_size=3)\n",
    "     | \"addpred\" >> beam.FlatMap(ModelPredict(PROJECT, REGION, ENDPOINT_ID))\n",
    "     | \"write\" >> beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Duu8mX3iXANE"
   },
   "source": [
    "## License\n",
    "Copyright 2022 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "09b_rest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
