{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "0uUeDqA32K9o",
    "outputId": "27b66765-ee49-4504-f32e-f34776c4f3b4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?name=Splitting+dataset+and+writing+TF+Records&download_url=https%3A%2F%2Fgithub.com%2Ftakumiohym%2Fpractical-ml-vision-book-ja%2Fraw%2Fmaster%2F05_create_dataset%2F05_split_tfrecord.ipynb\"><img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/>Run in Vertex AI Workbench</a></td><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/takumiohym/practical-ml-vision-book-ja/blob/master/05_create_dataset/05_split_tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"https://github.com/takumiohym/practical-ml-vision-book-ja/blob/master/05_create_dataset/05_split_tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td><td><a href=\"https://raw.githubusercontent.com/takumiohym/practical-ml-vision-book-ja/master/05_create_dataset/05_split_tfrecord.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a></td></table><br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "### change to reflect your notebook\n",
    "_nb_loc = \"05_create_dataset/05_split_tfrecord.ipynb\"\n",
    "_nb_title = \"Splitting dataset and writing TF Records\"\n",
    "\n",
    "_icons=[\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\", \"https://www.tensorflow.org/images/colab_logo_32px.png\", \"https://www.tensorflow.org/images/GitHub-Mark-32px.png\", \"https://www.tensorflow.org/images/download_logo_32px.png\"]\n",
    "_links=[\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?\" + urllib.parse.urlencode({\"name\": _nb_title, \"download_url\": \"https://github.com/takumiohym/practical-ml-vision-book-ja/raw/master/\"+_nb_loc}), \"https://colab.research.google.com/github/takumiohym/practical-ml-vision-book-ja/blob/master/{0}\".format(_nb_loc), \"https://github.com/takumiohym/practical-ml-vision-book-ja/blob/master/{0}\".format(_nb_loc), \"https://raw.githubusercontent.com/takumiohym/practical-ml-vision-book-ja/master/{0}\".format(_nb_loc)]\n",
    "md(\"\"\"<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"{0}\"><img src=\"{4}\"/>Run in Vertex AI Workbench</a></td><td><a target=\"_blank\" href=\"{1}\"><img src=\"{5}\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"{2}\"><img src=\"{6}\" />View source on GitHub</a></td><td><a href=\"{3}\"><img src=\"{7}\" />Download notebook</a></td></table><br/><br/>\"\"\".format(_links[0], _links[1], _links[2], _links[3], _icons[0], _icons[1], _icons[2], _icons[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gksy_Cqe2PND"
   },
   "source": [
    "# データセットの分割とTFRecordsの書き込み  \n",
    "\n",
    "このノートブックでは、データセットを学習用、検証用、テスト用に分割し、それらの画像をTensorFlow Recordsファイルに書き込む方法を示しています。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q apache-beam==2.38.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要に応じて、以下の`PROJECT`や`BUCKET`を変更してから実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config get-value project\n",
    "BUCKET=PROJECT[0]\n",
    "\n",
    "%env PROJECT=$PROJECT\n",
    "%env BUCKET=$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://practical-ml-vision-book/flowers_5_jpeg/f...</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://practical-ml-vision-book/flowers_5_jpeg/f...</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://practical-ml-vision-book/flowers_5_jpeg/f...</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://practical-ml-vision-book/flowers_5_jpeg/f...</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://practical-ml-vision-book/flowers_5_jpeg/f...</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  gs://practical-ml-vision-book/flowers_5_jpeg/f...  daisy\n",
       "1  gs://practical-ml-vision-book/flowers_5_jpeg/f...  daisy\n",
       "2  gs://practical-ml-vision-book/flowers_5_jpeg/f...  daisy\n",
       "3  gs://practical-ml-vision-book/flowers_5_jpeg/f...  daisy\n",
       "4  gs://practical-ml-vision-book/flowers_5_jpeg/f...  daisy"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/all_data.csv', names=['image','label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3670 2930 359 381\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "rnd = np.random.rand(len(df))\n",
    "train = df[ rnd < 0.8  ]\n",
    "valid = df[ (rnd >= 0.8) & (rnd < 0.9) ]\n",
    "test  = df[ rnd >= 0.9 ]\n",
    "print(len(df), len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf output\n",
    "mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('output/train.csv', header=False, index=False)\n",
    "valid.to_csv('output/valid.csv', header=False, index=False)\n",
    "test.to_csv('output/test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/10466290366_cc72e33532.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/10712722853_5632165b04.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/11642632_1e7627a2cc.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/13583238844_573df2de8e_m.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/1374193928_a52320eafa.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/13953307149_f8de6a768c_m.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/14471433500_cdaa22e3ea_m.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/14523675369_97c31d0b5b.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/163978992_8128b49d3e_n.jpg,daisy\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/16401288243_36112bd52f_m.jpg,daisy\n"
     ]
    }
   ],
   "source": [
    "!head output/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ApacheBeamを使用したTFレコードの書き込み  \n",
    "\n",
    "速度を上げるために、5つのレコードだけを書き込む方法を説明します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf = test.head()\n",
    "len(outdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/10466290366_cc72e33532.jpg',\n",
       "        'daisy'],\n",
       "       ['gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/10712722853_5632165b04.jpg',\n",
       "        'daisy'],\n",
       "       ['gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/11642632_1e7627a2cc.jpg',\n",
       "        'daisy'],\n",
       "       ['gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/13583238844_573df2de8e_m.jpg',\n",
       "        'daisy'],\n",
       "       ['gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/1374193928_a52320eafa.jpg',\n",
       "        'daisy']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy\n",
      "dandelion\n",
      "roses\n",
      "sunflowers\n",
      "tulips\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dict.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 5 labels, from daisy to tulips\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.io.gfile.GFile('gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dict.txt', 'r') as f:\n",
    "    LABELS = [line.rstrip() for line in f]\n",
    "print('Read in {} labels, from {} to {}'.format(\n",
    "    len(LABELS), LABELS[0], LABELS[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/10466290366_cc72e33532.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 14:14:55.829313: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/10712722853_5632165b04.jpg\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/11642632_1e7627a2cc.jpg\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/13583238844_573df2de8e_m.jpg\n",
      "gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/1374193928_a52320eafa.jpg\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import tensorflow as tf\n",
    "\n",
    "def _string_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode('utf-8')]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def read_and_decode(filename):\n",
    "    IMG_CHANNELS = 3\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def create_tfrecord(filename, label, label_int):\n",
    "    print(filename)\n",
    "    img = read_and_decode(filename)\n",
    "    dims = img.shape\n",
    "    img = tf.reshape(img, [-1]) # flatten to 1D array\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _float_feature(img),\n",
    "        'shape': _int64_feature([dims[0], dims[1], dims[2]]),\n",
    "        'label': _string_feature(label),\n",
    "        'label_int': _int64_feature([label_int])\n",
    "    })).SerializeToString()\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    (p \n",
    "     | 'input_df' >> beam.Create(outdf.values)\n",
    "     | 'create_tfrecord' >> beam.Map(lambda x: create_tfrecord(x[0], x[1], LABELS.index(x[1])))\n",
    "     | 'write' >> beam.io.tfrecordio.WriteToTFRecord('output/train')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jupyter jupyter 8777320 Jul 10 14:24 output/train-00000-of-00001\n",
      "-rw-r--r-- 1 jupyter jupyter  300932 Jul 10 14:14 output/train.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l output/train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hardcoded:  train a train True\n",
      "hardcoded:  train a valid False\n",
      "hardcoded:  train b train True\n",
      "hardcoded:  train b valid False\n",
      "hardcoded:  valid c train False\n",
      "hardcoded:  valid c valid True\n",
      "hardcoded:  valid d train False\n",
      "hardcoded:  valid d valid True\n"
     ]
    }
   ],
   "source": [
    "## splitting in Apache Beam\n",
    "def hardcoded(x, desired_split):\n",
    "    split, rec = x\n",
    "    print('hardcoded: ', split, rec, desired_split, split == desired_split)\n",
    "    if split == desired_split:\n",
    "        yield rec\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "        splits = (p\n",
    "                  | 'input_df' >> beam.Create([\n",
    "                      ('train', 'a'),\n",
    "                      ('train', 'b'),\n",
    "                      ('valid', 'c'),\n",
    "                      ('valid', 'd')\n",
    "                  ]))\n",
    "        \n",
    "        split = 'train'\n",
    "        _ = (splits\n",
    "                 | 'h_only_{}'.format(split) >> beam.FlatMap(\n",
    "                     lambda x: hardcoded(x, 'train'))\n",
    "         )        \n",
    "        split = 'valid'\n",
    "        _ = (splits\n",
    "                 | 'h_only_{}'.format(split) >> beam.FlatMap(\n",
    "                     lambda x: hardcoded(x, 'valid'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataflowで実行  \n",
    "\n",
    "Apache Beamコードは、Cloud Dataflowを使用してサーバーレスに実行できます。\n",
    "\n",
    "`./jpeg_to_tfrecord.py` にCloud Dataflow用のコードが用意されています。<br>\n",
    "beam.Pipeline() がクラウド上での実行用に以下のように書き換えられていることに注目してください。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "options = {\n",
    "      'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "      'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "      'job_name': JOBNAME,\n",
    "      'project': PROJECT,\n",
    "      'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "      'save_main_session': True\n",
    "  }\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "with beam.Pipeline(RUNNER, options=opts) as p:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m jpeg_to_tfrecord \\\n",
    "       --all_data gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/all_data.csv \\\n",
    "       --labels_file gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dict.txt \\\n",
    "       --project_id $PROJECT \\\n",
    "       --output_dir gs://${BUCKET}/data/flower_tfrecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dataflow_pipeline.png\" width=\"75%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil ls -l gs://${BUCKET}/data/flower_tfrecords/*-00001-*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_fNzWuY2UoB"
   },
   "source": [
    "## License\n",
    "Copyright 2022 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "05_split_tfrecord.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
