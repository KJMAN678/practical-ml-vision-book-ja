{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"data": {"text/markdown": ["<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=Object+Detection+with+RetinaNet+on+Arthropods+dataset+%2F+training&download_url=https%3A%2F%2Fgithub.com%2FGoogleCloudPlatform%2Fpractical-ml-vision-book%2Fraw%2Fmaster%2F04_detect_segment%2F04ab_retinanet_arthropods_train.ipynb\"><img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\"/>Run in AI Platform Notebook</a></td><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/04_detect_segment/04ab_retinanet_arthropods_train.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/04_detect_segment/04ab_retinanet_arthropods_train.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td><td><a href=\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/04_detect_segment/04ab_retinanet_arthropods_train.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a></td></table><br/><br/>"], "text/plain": ["<IPython.core.display.Markdown object>"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["import urllib\n", "from IPython.display import Markdown as md\n", "_nb_loc = \"04_detect_segment/04ab_retinanet_arthropods_train.ipynb\" # change to reflect your notebook\n", "_nb_title = \"Object Detection with RetinaNet on Arthropods dataset / training\" # change to reflect your notebook\n", "_nb_message = \"This notebook is set up to run on TPU or GPU. It has been executed on a TPUv3 but it works fine on TPUv2 (Colaboratory). Training on TPU requires a private writable GCS bucket. See the GCS bucket section below. This example uses the RetinaNet implementation from Tensorflow model Garden.\" # change to reflect your notebook\n", "_icons=[\"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/logo-cloud.png\", \"https://www.tensorflow.org/images/colab_logo_32px.png\", \"https://www.tensorflow.org/images/GitHub-Mark-32px.png\", \"https://www.tensorflow.org/images/download_logo_32px.png\"]\n", "_links=[\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?\" + urllib.parse.urlencode({\"name\": _nb_title, \"download_url\": \"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/raw/master/\"+_nb_loc}), \"https://colab.research.google.com/github/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\".format(_nb_loc), \"https://github.com/GoogleCloudPlatform/practical-ml-vision-book/blob/master/{0}\".format(_nb_loc), \"https://raw.githubusercontent.com/GoogleCloudPlatform/practical-ml-vision-book/master/{0}\".format(_nb_loc)]\n", "md(\"\"\"<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"{0}\"><img src=\"{4}\"/>Run in AI Platform Notebook</a></td><td><a target=\"_blank\" href=\"{1}\"><img src=\"{5}\" />Run in Google Colab</a></td><td><a target=\"_blank\" href=\"{2}\"><img src=\"{6}\" />View source on GitHub</a></td><td><a href=\"{3}\"><img src=\"{7}\" />Download notebook</a></td></table><br/><br/>\"\"\".format(_links[0], _links[1], _links[2], _links[3], _icons[0], _icons[1], _icons[2], _icons[3], _nb_title, _nb_message))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u7bc0\u8db3\u52d5\u7269\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8/\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3067\u306eRetinaNet\u306b\u3088\u308b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u691c\u51fa  \n", "\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306f\u3001TPU\u307e\u305f\u306fGPU\u3067\u5b9f\u884c\u3059\u308b\u3088\u3046\u306b\u8a2d\u5b9a\u3055\u308c\u3066\u3044\u307e\u3059\u3002 TPUv3\u3067\u5b9f\u884c\u3055\u308c\u307e\u3057\u305f\u304c\u3001TPUv2(Colaboratory)\u3067\u306f\u6b63\u5e38\u306b\u52d5\u4f5c\u3057\u307e\u3059\u3002 TPU\u3067\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306b\u306f\u3001\u66f8\u304d\u8fbc\u307f\u53ef\u80fd\u306a\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8GCS\u30d0\u30b1\u30c3\u30c8\u304c\u5fc5\u8981\u3067\u3059\u3002\u4ee5\u4e0b\u306eGCS\u30d0\u30b1\u30c3\u30c8\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u3053\u306e\u4f8b\u3067\u306f\u3001Tensorflow\u30e2\u30c7\u30ebGarden\u306eRetinaNet\u5b9f\u88c5\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["!pip install --quiet tf-models-official==2.5\n", "# please restart the kernel after installs"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Tensorflow version 2.7.0\n"]}], "source": ["import time, re, os\n", "import tensorflow as tf\n", "import numpy as np\n", "import pprint as pp\n", "AUTO = tf.data.AUTOTUNE\n", "print(\"Tensorflow version\", tf.__version__)\n", "\n", "# Tensorflow Model Garden imports\n", "import official as model_garden\n", "from official.vision.beta.configs import retinanet as retinanet_cfg\n", "from official.vision.beta.configs import backbones as backbones_cfg\n", "from official.vision.beta.serving import export_saved_model_lib\n", "from official.core import train_lib\n", "\n", "# TODO\n", "# load the backbone checkpoint from the official loacation as soon as it is published\n", "# save the model configuration to the saved_odel folder as per best practices"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# GCS\u30d0\u30b1\u30c3\u30c8  \n", "\u3053\u306e\u30d0\u30b1\u30c3\u30c8\u306f\u4ee5\u4e0b\u3092\u53d7\u3051\u53d6\u308a\u307e\u3059\u3002  \n", " - \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u30d5\u30a9\u30ed\u30fc\u3067\u304d\u308b\u30c6\u30f3\u30bd\u30eb\u30dc\u30fc\u30c9\u306e\u6982\u8981  \n", " - \u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8  \n", " - \u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u5f8c\u306b\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb  \n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Use your own GCS bucket here. GCS is required if training on TPU.\n", "# On GPU, a local folder will work.\n", "MODEL_ARTIFACT_BUCKET = 'gs://ml1-demo-martin/arthropod_jobs/'\n", "MODEL_DIR = MODEL_ARTIFACT_BUCKET + str(int(time.time()))\n", "\n", "# If you are running on Colaboratory, you must authenticate\n", "# for Colab to have write access to the bucket.\n", "\n", "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n", "if IS_COLAB_BACKEND:\n", "    from google.colab import auth\n", "    auth.authenticate_user()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# TPU/GPU\u691c\u51fa"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]}, {"name": "stderr", "output_type": "stream", "text": ["2021-11-24 23:20:33.980914: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n", "2021-11-24 23:20:34.013046: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.28.166.186:8470}\n", "2021-11-24 23:20:34.013088: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:38932}\n", "2021-11-24 23:20:34.031838: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> 10.28.166.186:8470}\n", "2021-11-24 23:20:34.031883: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:38932}\n", "2021-11-24 23:20:34.035122: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:427] Started server with target: grpc://localhost:38932\n", "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Initializing the TPU system: martin-tpuv3-8-tf27\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:Initializing the TPU system: martin-tpuv3-8-tf27\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Finished initializing TPU system.\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:Finished initializing TPU system.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Found TPU system:\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:Found TPU system:\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Num TPU Cores: 8\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Num TPU Cores: 8\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Num TPU Workers: 1\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Num TPU Workers: 1\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["REPLICAS:  8\n"]}], "source": ["strategy = tf.distribute.get_strategy()\n", "\n", "try: # detect TPUs\n", "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n", "    strategy = tf.distribute.TPUStrategy(tpu)\n", "except ValueError: # detect GPUs or multi-GPU machines\n", "    strategy = tf.distribute.MirroredStrategy()\n", "\n", "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u69cb\u6210"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Model dir: gs://ml1-demo-martin/arthropod_jobs/1637796032\n"]}], "source": ["TRAIN_DATA_PATH_PATTERN = 'gs://practical-ml-vision-book/arthropod_detection_tfr/size_w1024px/*.train.tfrec'\n", "VALID_DATA_PATH_PATTERN = 'gs://practical-ml-vision-book/arthropod_detection_tfr/size_w1024px/*.test.tfrec'\n", "SPINET_MOBILE_CHECKPOINT = 'gs://practical-ml-vision-book/arthropod_detection_tfr/spinenet_mobile_checkpoint/'\n", "\n", "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n", "\n", "EPOCHS = 80\n", "\n", "RAW_CLASSES = ['Lepidoptera', 'Hymenoptera', 'Hemiptera', 'Odonata', 'Diptera', 'Araneae', 'Coleoptera',\n", "               '_truncated', '_blurred', '_occluded', ]\n", "CLASSES = [klass for klass in RAW_CLASSES if klass not in ['_truncated', '_blurred', '_occluded']]\n", "\n", "# Lepidoptera = butterfies and moths\n", "# Hymenoptera = wasps, bees and ants\n", "# Hemiptera = true bugs (cicadas, aphids, shield bugs, ...)\n", "# Odonata = dragonflies\n", "# Diptera = fies\n", "# Araneae = spiders\n", "# Coleoptera = beetles\n", "\n", "# NOT IN DATASET\n", "# Orthoptera = grasshoppers\n", "\n", "print(\"Model dir:\", MODEL_DIR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u30c7\u30fc\u30bf\u30d5\u30a1\u30a4\u30eb\u3092\u30ed\u30fc\u30c9\u3059\u308b  \n", "\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u3059\u3067\u306bTFRecord\u5f62\u5f0f\u3067\u6e96\u5099\u3055\u308c\u3066\u3044\u307e\u3059\u3002<br/>  \n", "\u30c7\u30fc\u30bf\u3092\u6e96\u5099\u3057\u305f\u30b9\u30af\u30ea\u30d7\u30c8\u306f\u300c04aa_retinanet_arthropods_dataprep.ipynb\u300d\u306b\u3042\u308a\u307e\u3059<br/>  \n", "TFRecord\u30d5\u30a1\u30a4\u30eb\u3092\u624b\u52d5\u3067\u89e3\u6790\u3057\u3001\u305d\u306e\u5185\u5bb9\u3092\u8996\u899a\u5316\u3059\u308b\u306b\u306f\u3001\u300c04ac_retinanet_arthropods_predict.ipynb\u300d\u306e\u30b3\u30fc\u30c9\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training dataset:\n", "    24 TFRecord files.\n", "    11544 images\n", "    Steps per epoch: 45\n", "\n", "Validation dataset:\n", "    8 TFRecord files.\n", "    3832 images\n", "    Validation steps: 14\n", "\n", "Global batch size: 256\n"]}], "source": ["def count_data_items(filenames):\n", "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n", "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n", "    return int(np.sum(n))\n", "\n", "TRAIN_FILENAMES = tf.io.gfile.glob(TRAIN_DATA_PATH_PATTERN)\n", "NB_TRAIN_IMAGES = count_data_items(TRAIN_FILENAMES)\n", "STEPS_PER_EPOCH = NB_TRAIN_IMAGES // BATCH_SIZE\n", "\n", "VALID_FILENAMES = tf.io.gfile.glob(VALID_DATA_PATH_PATTERN)\n", "NB_VALID_IMAGES = count_data_items(VALID_FILENAMES)\n", "VALID_STEPS = NB_VALID_IMAGES // BATCH_SIZE\n", "\n", "print(\"Training dataset:\")\n", "print(f\"    {len(TRAIN_FILENAMES)} TFRecord files.\")\n", "print(f\"    {NB_TRAIN_IMAGES} images\")\n", "print(\"    Steps per epoch:\", STEPS_PER_EPOCH)\n", "print()\n", "print(\"Validation dataset:\")\n", "print(f\"    {len(VALID_FILENAMES)} TFRecord files.\")\n", "print(f\"    {NB_VALID_IMAGES} images\")\n", "print(\"    Validation steps:\", VALID_STEPS)\n", "print()\n", "print(\"Global batch size:\", BATCH_SIZE)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u30e2\u30c7\u30eb\u69cb\u6210"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'runtime': {'all_reduce_alg': None,\n", "             'batchnorm_spatial_persistent': False,\n", "             'dataset_num_private_threads': None,\n", "             'default_shard_dim': -1,\n", "             'distribution_strategy': 'mirrored',\n", "             'enable_xla': False,\n", "             'gpu_thread_mode': None,\n", "             'loss_scale': None,\n", "             'mixed_precision_dtype': None,\n", "             'num_cores_per_replica': 1,\n", "             'num_gpus': 0,\n", "             'num_packs': 1,\n", "             'per_gpu_thread_count': 0,\n", "             'run_eagerly': False,\n", "             'task_index': -1,\n", "             'tpu': None,\n", "             'tpu_enable_xla_dynamic_padder': None,\n", "             'worker_hosts': None},\n", " 'task': {'annotation_file': None,\n", "          'init_checkpoint': 'gs://practical-ml-vision-book/arthropod_detection_tfr/spinenet_mobile_checkpoint/',\n", "          'init_checkpoint_modules': 'backbone',\n", "          'losses': {'box_loss_weight': 50,\n", "                     'focal_loss_alpha': 0.25,\n", "                     'focal_loss_gamma': 1.5,\n", "                     'huber_loss_delta': 0.1,\n", "                     'l2_weight_decay': 0.0},\n", "          'model': {'anchor': {'anchor_size': 4.0,\n", "                               'aspect_ratios': [0.5, 1.0, 2.0],\n", "                               'num_scales': 3},\n", "                    'backbone': {'spinenet_mobile': {'expand_ratio': 6,\n", "                                                     'model_id': '49',\n", "                                                     'se_ratio': 0.2,\n", "                                                     'stochastic_depth_drop_rate': 0.0},\n", "                                 'type': 'spinenet_mobile'},\n", "                    'decoder': {'fpn': {'num_filters': 256,\n", "                                        'use_separable_conv': False},\n", "                                'type': 'fpn'},\n", "                    'detection_generator': {'max_num_detections': 100,\n", "                                            'nms_iou_threshold': 0.5,\n", "                                            'pre_nms_score_threshold': 0.05,\n", "                                            'pre_nms_top_k': 5000,\n", "                                            'use_batched_nms': False},\n", "                    'head': {'num_convs': 4,\n", "                             'num_filters': 256,\n", "                             'use_separable_conv': False},\n", "                    'input_size': [384, 384, 3],\n", "                    'max_level': 7,\n", "                    'min_level': 3,\n", "                    'norm_activation': {'activation': 'relu',\n", "                                        'norm_epsilon': 0.001,\n", "                                        'norm_momentum': 0.99,\n", "                                        'use_sync_bn': True},\n", "                    'num_classes': 8},\n", "          'per_category_metrics': False,\n", "          'train_data': {'block_length': 1,\n", "                         'cache': False,\n", "                         'cycle_length': None,\n", "                         'decoder': {'simple_decoder': {'regenerate_source_id': False},\n", "                                     'type': 'simple_decoder'},\n", "                         'deterministic': None,\n", "                         'drop_remainder': True,\n", "                         'dtype': 'bfloat16',\n", "                         'enable_tf_data_service': False,\n", "                         'file_type': 'tfrecord',\n", "                         'global_batch_size': 256,\n", "                         'input_path': 'gs://practical-ml-vision-book/arthropod_detection_tfr/size_w1024px/*.train.tfrec',\n", "                         'is_training': True,\n", "                         'parser': {'aug_rand_hflip': True,\n", "                                    'aug_scale_max': 2.0,\n", "                                    'aug_scale_min': 0.7,\n", "                                    'match_threshold': 0.5,\n", "                                    'max_num_instances': 100,\n", "                                    'num_channels': 3,\n", "                                    'skip_crowd_during_training': True,\n", "                                    'unmatched_threshold': 0.5},\n", "                         'seed': None,\n", "                         'sharding': True,\n", "                         'shuffle_buffer_size': 10000,\n", "                         'tf_data_service_address': None,\n", "                         'tf_data_service_job_name': None,\n", "                         'tfds_as_supervised': False,\n", "                         'tfds_data_dir': '',\n", "                         'tfds_name': '',\n", "                         'tfds_skip_decoding_feature': '',\n", "                         'tfds_split': ''},\n", "          'validation_data': {'block_length': 1,\n", "                              'cache': False,\n", "                              'cycle_length': None,\n", "                              'decoder': {'simple_decoder': {'regenerate_source_id': False},\n", "                                          'type': 'simple_decoder'},\n", "                              'deterministic': None,\n", "                              'drop_remainder': True,\n", "                              'dtype': 'bfloat16',\n", "                              'enable_tf_data_service': False,\n", "                              'file_type': 'tfrecord',\n", "                              'global_batch_size': 256,\n", "                              'input_path': 'gs://practical-ml-vision-book/arthropod_detection_tfr/size_w1024px/*.test.tfrec',\n", "                              'is_training': False,\n", "                              'parser': {'aug_rand_hflip': False,\n", "                                         'aug_scale_max': 1.0,\n", "                                         'aug_scale_min': 1.0,\n", "                                         'match_threshold': 0.5,\n", "                                         'max_num_instances': 100,\n", "                                         'num_channels': 3,\n", "                                         'skip_crowd_during_training': True,\n", "                                         'unmatched_threshold': 0.5},\n", "                              'seed': None,\n", "                              'sharding': True,\n", "                              'shuffle_buffer_size': 10000,\n", "                              'tf_data_service_address': None,\n", "                              'tf_data_service_job_name': None,\n", "                              'tfds_as_supervised': False,\n", "                              'tfds_data_dir': '',\n", "                              'tfds_name': '',\n", "                              'tfds_skip_decoding_feature': '',\n", "                              'tfds_split': ''}},\n", " 'trainer': {'allow_tpu_summary': False,\n", "             'best_checkpoint_eval_metric': '',\n", "             'best_checkpoint_export_subdir': '',\n", "             'best_checkpoint_metric_comp': 'higher',\n", "             'checkpoint_interval': 360,\n", "             'continuous_eval_timeout': 3600,\n", "             'eval_tf_function': True,\n", "             'eval_tf_while_loop': False,\n", "             'loss_upper_bound': 1000000.0,\n", "             'max_to_keep': 5,\n", "             'optimizer_config': {'ema': None,\n", "                                  'learning_rate': {'stepwise': {'boundaries': [675,\n", "                                                                                1350,\n", "                                                                                2025,\n", "                                                                                2700,\n", "                                                                                3375],\n", "                                                                 'name': 'PiecewiseConstantDecay',\n", "                                                                 'values': [0.016,\n", "                                                                            0.008,\n", "                                                                            0.004,\n", "                                                                            0.002,\n", "                                                                            0.001,\n", "                                                                            0.0005]},\n", "                                                    'type': 'stepwise'},\n", "                                  'optimizer': {'sgd': {'clipnorm': None,\n", "                                                        'clipvalue': None,\n", "                                                        'decay': 0.0,\n", "                                                        'global_clipnorm': None,\n", "                                                        'momentum': 0.9,\n", "                                                        'name': 'SGD',\n", "                                                        'nesterov': False},\n", "                                                'type': 'sgd'},\n", "                                  'warmup': {'type': None}},\n", "             'recovery_begin_steps': 0,\n", "             'recovery_max_trials': 0,\n", "             'steps_per_loop': 45,\n", "             'summary_interval': 45,\n", "             'train_steps': 3600,\n", "             'train_tf_function': True,\n", "             'train_tf_while_loop': True,\n", "             'validation_interval': 360,\n", "             'validation_steps': 14}}\n"]}], "source": ["IMAGE_SIZE = [384, 384]\n", "\n", "# default parameters can be overriden in two ways:\n", "# 1) params.override({'task': {'model': {'backbone': backbone_cfg.as_dict()}}})\n", "# 2) params.task.model.backbone = backbone_cfg\n", "# params.override checks that the dictionary keys exist\n", "# the second options will silently add new keys\n", "\n", "params = model_garden.core.exp_factory.get_exp_config('retinanet')\n", "\n", "params.task.model.num_classes = len(CLASSES)+1 # class 0 is reserved for backgrounds\n", "params.task.model.input_size = [*IMAGE_SIZE, 3] # this automatically configures the input reader to random crop training images\n", "params.task.init_checkpoint = SPINET_MOBILE_CHECKPOINT\n", "params.task.init_checkpoint_modules = 'backbone'\n", "params.task.model.backbone = backbones_cfg.Backbone(type='spinenet_mobile', spinenet_mobile=backbones_cfg.SpineNetMobile())\n", "\n", "train_data_cfg=retinanet_cfg.DataConfig(\n", "    input_path=TRAIN_DATA_PATH_PATTERN,\n", "    is_training=True,\n", "    global_batch_size=BATCH_SIZE,\n", "    parser=retinanet_cfg.Parser(aug_rand_hflip=True, aug_scale_min=0.7, aug_scale_max=2.0))\n", "\n", "valid_data_cfg=retinanet_cfg.DataConfig(\n", "    input_path=VALID_DATA_PATH_PATTERN,\n", "    is_training=False,\n", "    global_batch_size=BATCH_SIZE)\n", "\n", "params.override({'task': {'train_data': train_data_cfg.as_dict(), 'validation_data': valid_data_cfg.as_dict()}})\n", "\n", "trainer_cfg=model_garden.core.config_definitions.TrainerConfig(\n", "    train_steps=EPOCHS * STEPS_PER_EPOCH,\n", "    validation_steps=VALID_STEPS,\n", "    validation_interval=8*STEPS_PER_EPOCH,\n", "    steps_per_loop=STEPS_PER_EPOCH,\n", "    summary_interval=STEPS_PER_EPOCH,\n", "    checkpoint_interval=8*STEPS_PER_EPOCH)\n", "\n", "optim_cfg = model_garden.modeling.optimization.OptimizationConfig({\n", "    'optimizer': {\n", "                  'type': 'sgd',\n", "                  'sgd': {'momentum': 0.9}},\n", "    'learning_rate': {'type': 'stepwise',\n", "                      'stepwise': {'boundaries': [15 * STEPS_PER_EPOCH,\n", "                                                  30 * STEPS_PER_EPOCH,\n", "                                                  45 * STEPS_PER_EPOCH,\n", "                                                  60 * STEPS_PER_EPOCH,\n", "                                                  75 * STEPS_PER_EPOCH],\n", "                                   'values': [0.016, #0.01,\n", "                                              0.008, #0.005,\n", "                                              0.004, #0.0025,\n", "                                              0.002, #0.001,\n", "                                              0.001, #0.0005,\n", "                                              0.0005]} #0.00025]}\n", "                     },\n", "    #'warmup': {'type': 'linear','linear': {'warmup_steps': 5*STEPS_PER_EPOCH, 'warmup_learning_rate': 0.00001}}\n", "})\n", "\n", "trainer_cfg.override({'optimizer_config': optim_cfg})\n", "params.override({'trainer': trainer_cfg})\n", "\n", "pp.pprint(params.as_dict())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3059\u308b"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["task = model_garden.core.task_factory.get_task(params.task, logging_dir=MODEL_DIR)\n", "\n", "# this works too:\n", "#task = official.vision.beta.tasks.retinanet.RetinaNetTask(params.task)\n", "\n", "# this returns a RetinaNetModel\n", "#task.build_model()\n", "# note: none of the expected model functionalities work: model.fit(), model.predict(), model.save()\n", "\n", "# this returns the training dataset\n", "#train_dataset = task.build_inputs(train_data_cfg)\n", "# note: the dataset already includes FPN level and anchor pairing and is therefore not very readable\n", "\n", "# this returns the validation dataset\n", "#valid_dataset = task.build_inputs(valid_data_cfg)\n", "# note: the dataset already includes FPN level and anchor pairing and is therefore not very readable\n", "\n", "# this code allows you to see if the TFRecord fields are read correctly\n", "#ds = tf.data.TFRecordDataset(tf.io.gfile.glob(TRAIN_DATA_PATH_PATTERN))\n", "#dec = official.vision.beta.dataloaders.tf_example_decoder.TfExampleDecoder()\n", "#ds = ds.map(dec.decode)\n", "\n", "# training and validatoin data parsing happens in:\n", "# official.vision.beta.dataloaders.retinanet_input.Parser._parse_train_data\n", "# official.vision.beta.dataloaders.retinanet_input.Parser._parse_eval_data\n", "# official.vision.beta.dataloaders.Parser.parse() # dispatches between _parse_train_data and _parse_eval_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b  \n", "\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306b\u306f\u3001TPUv3-8\u3067\u7d0430\u5206\u3001Colab\u306eTPUv2-8\u306740\u5206\u304b\u304b\u308a\u307e\u3059\u3002"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"scrolled": true, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["gs://ml1-demo-martin/arthropod_jobs/1637796032\n", "restoring or initializing model...\n", "initialized model.\n", "train | step:      0 | training until step 360...\n", "train | step:     45 | steps/sec:    0.1 | output: \n", "    {'box_loss': 0.009556498,\n", "     'cls_loss': 0.90980715,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 1.3876321,\n", "     'total_loss': 1.3876321,\n", "     'training_loss': 1.3876321}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-45.\n", "train | step:     90 | steps/sec:    1.8 | output: \n", "    {'box_loss': 0.005307368,\n", "     'cls_loss': 0.63911986,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.90448844,\n", "     'total_loss': 0.90448844,\n", "     'training_loss': 0.90448844}\n", "train | step:    135 | steps/sec:    2.8 | output: \n", "    {'box_loss': 0.004365041,\n", "     'cls_loss': 0.5586993,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.77695125,\n", "     'total_loss': 0.77695125,\n", "     'training_loss': 0.77695125}\n", "train | step:    180 | steps/sec:    2.6 | output: \n", "    {'box_loss': 0.0039574234,\n", "     'cls_loss': 0.5234108,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.721282,\n", "     'total_loss': 0.721282,\n", "     'training_loss': 0.721282}\n", "train | step:    225 | steps/sec:    2.7 | output: \n", "    {'box_loss': 0.003681702,\n", "     'cls_loss': 0.49403378,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.67811877,\n", "     'total_loss': 0.67811877,\n", "     'training_loss': 0.67811877}\n", "train | step:    270 | steps/sec:    2.6 | output: \n", "    {'box_loss': 0.003496634,\n", "     'cls_loss': 0.47317967,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.6480113,\n", "     'total_loss': 0.6480113,\n", "     'training_loss': 0.6480113}\n", "train | step:    315 | steps/sec:    2.6 | output: \n", "    {'box_loss': 0.0032965434,\n", "     'cls_loss': 0.44756672,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.612394,\n", "     'total_loss': 0.612394,\n", "     'training_loss': 0.612394}\n", "train | step:    360 | steps/sec:    2.5 | output: \n", "    {'box_loss': 0.0032442657,\n", "     'cls_loss': 0.43660975,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.5988229,\n", "     'total_loss': 0.5988229,\n", "     'training_loss': 0.5988229}\n", " eval | step:    360 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=16.45s).\n", "Accumulating evaluation results...\n", "DONE (t=4.30s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.430\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.289\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.288\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.487\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.559\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.071\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610\n", " eval | step:    360 | eval time:   81.3 sec | output: \n", "    {'AP': 0.26832336,\n", "     'AP50': 0.4300787,\n", "     'AP75': 0.28862187,\n", "     'APl': 0.28750116,\n", "     'APm': 0.015297678,\n", "     'APs': 0.0,\n", "     'ARl': 0.61047405,\n", "     'ARm': 0.0706937,\n", "     'ARmax1': 0.48737863,\n", "     'ARmax10': 0.5594851,\n", "     'ARmax100': 0.5661079,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0037560686,\n", "     'cls_loss': 0.5365863,\n", "     'model_loss': 0.72438973,\n", "     'total_loss': 0.72438973,\n", "     'validation_loss': 0.72438973}\n", "train | step:    360 | training until step 720...\n", "train | step:    405 | steps/sec:    0.4 | output: \n", "    {'box_loss': 0.003196666,\n", "     'cls_loss': 0.42111766,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.58095086,\n", "     'total_loss': 0.58095086,\n", "     'training_loss': 0.58095086}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-405.\n", "train | step:    450 | steps/sec:    2.0 | output: \n", "    {'box_loss': 0.0029801917,\n", "     'cls_loss': 0.40611297,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.5551226,\n", "     'total_loss': 0.5551226,\n", "     'training_loss': 0.5551226}\n", "train | step:    495 | steps/sec:    3.0 | output: \n", "    {'box_loss': 0.0029069097,\n", "     'cls_loss': 0.39142147,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.5367669,\n", "     'total_loss': 0.5367669,\n", "     'training_loss': 0.5367669}\n", "train | step:    540 | steps/sec:    2.7 | output: \n", "    {'box_loss': 0.0028927405,\n", "     'cls_loss': 0.38078177,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.5254188,\n", "     'total_loss': 0.5254188,\n", "     'training_loss': 0.5254188}\n", "train | step:    585 | steps/sec:    2.7 | output: \n", "    {'box_loss': 0.002818517,\n", "     'cls_loss': 0.36946267,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.5103886,\n", "     'total_loss': 0.5103886,\n", "     'training_loss': 0.5103886}\n", "train | step:    630 | steps/sec:    2.5 | output: \n", "    {'box_loss': 0.002743276,\n", "     'cls_loss': 0.363299,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.5004627,\n", "     'total_loss': 0.5004627,\n", "     'training_loss': 0.5004627}\n", "train | step:    675 | steps/sec:    2.6 | output: \n", "    {'box_loss': 0.0027198468,\n", "     'cls_loss': 0.35987926,\n", "     'learning_rate': 0.016,\n", "     'model_loss': 0.4958716,\n", "     'total_loss': 0.4958716,\n", "     'training_loss': 0.4958716}\n", "train | step:    720 | steps/sec:    2.7 | output: \n", "    {'box_loss': 0.0026025185,\n", "     'cls_loss': 0.3406233,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.4707493,\n", "     'total_loss': 0.4707493,\n", "     'training_loss': 0.4707493}\n", " eval | step:    720 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=18.73s).\n", "Accumulating evaluation results...\n", "DONE (t=4.50s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.585\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.431\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.536\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.611\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.120\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.665\n", " eval | step:    720 | eval time:   54.0 sec | output: \n", "    {'AP': 0.39413595,\n", "     'AP50': 0.5847048,\n", "     'AP75': 0.43115857,\n", "     'APl': 0.42292807,\n", "     'APm': 0.03156409,\n", "     'APs': 0.0,\n", "     'ARl': 0.66479313,\n", "     'ARm': 0.120165594,\n", "     'ARmax1': 0.53558916,\n", "     'ARmax10': 0.611178,\n", "     'ARmax100': 0.6198528,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0031289435,\n", "     'cls_loss': 0.42072892,\n", "     'model_loss': 0.57717615,\n", "     'total_loss': 0.57717615,\n", "     'validation_loss': 0.57717615}\n", "train | step:    720 | training until step 1080...\n", "train | step:    765 | steps/sec:    0.6 | output: \n", "    {'box_loss': 0.0025358277,\n", "     'cls_loss': 0.33305147,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.4598429,\n", "     'total_loss': 0.4598429,\n", "     'training_loss': 0.4598429}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-765.\n", "train | step:    810 | steps/sec:    2.0 | output: \n", "    {'box_loss': 0.0025076002,\n", "     'cls_loss': 0.3298932,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.4552733,\n", "     'total_loss': 0.4552733,\n", "     'training_loss': 0.4552733}\n", "train | step:    855 | steps/sec:    3.4 | output: \n", "    {'box_loss': 0.0024614497,\n", "     'cls_loss': 0.31960323,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.44267583,\n", "     'total_loss': 0.44267583,\n", "     'training_loss': 0.44267583}\n", "train | step:    900 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0024891277,\n", "     'cls_loss': 0.3195183,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.44397464,\n", "     'total_loss': 0.44397464,\n", "     'training_loss': 0.44397464}\n", "train | step:    945 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0024845337,\n", "     'cls_loss': 0.31656307,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.44078976,\n", "     'total_loss': 0.44078976,\n", "     'training_loss': 0.44078976}\n", "train | step:    990 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0024048975,\n", "     'cls_loss': 0.31188053,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.43212542,\n", "     'total_loss': 0.43212542,\n", "     'training_loss': 0.43212542}\n", "train | step:   1035 | steps/sec:    2.5 | output: \n", "    {'box_loss': 0.0024089003,\n", "     'cls_loss': 0.30855688,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.42900178,\n", "     'total_loss': 0.42900178,\n", "     'training_loss': 0.42900178}\n", "train | step:   1080 | steps/sec:    2.5 | output: \n", "    {'box_loss': 0.002367836,\n", "     'cls_loss': 0.30211505,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.4205069,\n", "     'total_loss': 0.4205069,\n", "     'training_loss': 0.4205069}\n", " eval | step:   1080 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=30.20s).\n", "Accumulating evaluation results...\n", "DONE (t=7.51s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.635\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.486\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.030\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.551\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.629\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.130\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.681\n", " eval | step:   1080 | eval time:   71.8 sec | output: \n", "    {'AP': 0.4395279,\n", "     'AP50': 0.6351018,\n", "     'AP75': 0.48583257,\n", "     'APl': 0.47268134,\n", "     'APm': 0.029759092,\n", "     'APs': 0.0,\n", "     'ARl': 0.6810471,\n", "     'ARm': 0.13044845,\n", "     'ARmax1': 0.5510549,\n", "     'ARmax10': 0.62891674,\n", "     'ARmax100': 0.63586366,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0029519496,\n", "     'cls_loss': 0.3816042,\n", "     'model_loss': 0.52920175,\n", "     'total_loss': 0.52920175,\n", "     'validation_loss': 0.52920175}\n", "train | step:   1080 | training until step 1440...\n", "train | step:   1125 | steps/sec:    0.5 | output: \n", "    {'box_loss': 0.0023988287,\n", "     'cls_loss': 0.30283782,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.4227792,\n", "     'total_loss': 0.4227792,\n", "     'training_loss': 0.4227792}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-1125.\n", "train | step:   1170 | steps/sec:    1.8 | output: \n", "    {'box_loss': 0.00241824,\n", "     'cls_loss': 0.3003762,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.42128822,\n", "     'total_loss': 0.42128822,\n", "     'training_loss': 0.42128822}\n", "train | step:   1215 | steps/sec:    3.4 | output: \n", "    {'box_loss': 0.0023461268,\n", "     'cls_loss': 0.29723275,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.41453904,\n", "     'total_loss': 0.41453904,\n", "     'training_loss': 0.41453904}\n", "train | step:   1260 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0023003963,\n", "     'cls_loss': 0.29182583,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.40684563,\n", "     'total_loss': 0.40684563,\n", "     'training_loss': 0.40684563}\n", "train | step:   1305 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.00229992,\n", "     'cls_loss': 0.28828892,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.40328488,\n", "     'total_loss': 0.40328488,\n", "     'training_loss': 0.40328488}\n", "train | step:   1350 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0022527974,\n", "     'cls_loss': 0.28270146,\n", "     'learning_rate': 0.008,\n", "     'model_loss': 0.39534134,\n", "     'total_loss': 0.39534134,\n", "     'training_loss': 0.39534134}\n", "train | step:   1395 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0022971758,\n", "     'cls_loss': 0.2839757,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.3988345,\n", "     'total_loss': 0.3988345,\n", "     'training_loss': 0.3988345}\n", "train | step:   1440 | steps/sec:    2.1 | output: \n", "    {'box_loss': 0.0022499117,\n", "     'cls_loss': 0.27730593,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.3898015,\n", "     'total_loss': 0.3898015,\n", "     'training_loss': 0.3898015}\n", " eval | step:   1440 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=21.92s).\n", "Accumulating evaluation results...\n", "DONE (t=6.11s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.509\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.030\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.499\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.560\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.635\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.127\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.688\n", " eval | step:   1440 | eval time:   65.3 sec | output: \n", "    {'AP': 0.46322942,\n", "     'AP50': 0.66332775,\n", "     'AP75': 0.50923884,\n", "     'APl': 0.4986061,\n", "     'APm': 0.02960428,\n", "     'APs': 0.0,\n", "     'ARl': 0.6884273,\n", "     'ARm': 0.12729502,\n", "     'ARmax1': 0.5600275,\n", "     'ARmax10': 0.6354349,\n", "     'ARmax100': 0.6425564,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0028825796,\n", "     'cls_loss': 0.3665981,\n", "     'model_loss': 0.51072705,\n", "     'total_loss': 0.51072705,\n", "     'validation_loss': 0.51072705}\n", "train | step:   1440 | training until step 1800...\n", "train | step:   1485 | steps/sec:    0.5 | output: \n", "    {'box_loss': 0.0022144045,\n", "     'cls_loss': 0.27389258,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.38461286,\n", "     'total_loss': 0.38461286,\n", "     'training_loss': 0.38461286}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-1485.\n", "train | step:   1530 | steps/sec:    1.9 | output: \n", "    {'box_loss': 0.0022185734,\n", "     'cls_loss': 0.27217346,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.3831022,\n", "     'total_loss': 0.3831022,\n", "     'training_loss': 0.3831022}\n", "train | step:   1575 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0022311488,\n", "     'cls_loss': 0.27272242,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.38427985,\n", "     'total_loss': 0.38427985,\n", "     'training_loss': 0.38427985}\n", "train | step:   1620 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0021750403,\n", "     'cls_loss': 0.26941618,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.3781682,\n", "     'total_loss': 0.3781682,\n", "     'training_loss': 0.3781682}\n", "train | step:   1665 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0021478464,\n", "     'cls_loss': 0.26604265,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.3734349,\n", "     'total_loss': 0.3734349,\n", "     'training_loss': 0.3734349}\n", "train | step:   1710 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0022108867,\n", "     'cls_loss': 0.2689062,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.37945056,\n", "     'total_loss': 0.37945056,\n", "     'training_loss': 0.37945056}\n", "train | step:   1755 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.002198734,\n", "     'cls_loss': 0.26622543,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.37616217,\n", "     'total_loss': 0.37616217,\n", "     'training_loss': 0.37616217}\n", "train | step:   1800 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.0021151032,\n", "     'cls_loss': 0.26110482,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.36685994,\n", "     'total_loss': 0.36685994,\n", "     'training_loss': 0.36685994}\n", " eval | step:   1800 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=15.64s).\n", "Accumulating evaluation results...\n", "DONE (t=4.04s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.470\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.674\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.514\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.506\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.563\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.638\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692\n", " eval | step:   1800 | eval time:   59.8 sec | output: \n", "    {'AP': 0.47003204,\n", "     'AP50': 0.67361885,\n", "     'AP75': 0.5141746,\n", "     'APl': 0.5057134,\n", "     'APm': 0.031449683,\n", "     'APs': 0.0,\n", "     'ARl': 0.691569,\n", "     'ARm': 0.14593986,\n", "     'ARmax1': 0.5632995,\n", "     'ARmax10': 0.6379285,\n", "     'ARmax100': 0.64693797,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0028204843,\n", "     'cls_loss': 0.3576336,\n", "     'model_loss': 0.4986578,\n", "     'total_loss': 0.4986578,\n", "     'validation_loss': 0.4986578}\n", "train | step:   1800 | training until step 2160...\n", "train | step:   1845 | steps/sec:    0.5 | output: \n", "    {'box_loss': 0.0021538176,\n", "     'cls_loss': 0.26374215,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.37143308,\n", "     'total_loss': 0.37143308,\n", "     'training_loss': 0.37143308}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-1845.\n", "train | step:   1890 | steps/sec:    1.9 | output: \n", "    {'box_loss': 0.0022076895,\n", "     'cls_loss': 0.26280192,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.37318638,\n", "     'total_loss': 0.37318638,\n", "     'training_loss': 0.37318638}\n", "train | step:   1935 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0021441204,\n", "     'cls_loss': 0.25935933,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.36656532,\n", "     'total_loss': 0.36656532,\n", "     'training_loss': 0.36656532}\n", "train | step:   1980 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.002142912,\n", "     'cls_loss': 0.25962898,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.3667746,\n", "     'total_loss': 0.3667746,\n", "     'training_loss': 0.3667746}\n", "train | step:   2025 | steps/sec:    2.3 | output: \n", "    {'box_loss': 0.0021255855,\n", "     'cls_loss': 0.2578761,\n", "     'learning_rate': 0.004,\n", "     'model_loss': 0.3641553,\n", "     'total_loss': 0.3641553,\n", "     'training_loss': 0.3641553}\n", "train | step:   2070 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0021206033,\n", "     'cls_loss': 0.25572133,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.36175153,\n", "     'total_loss': 0.36175153,\n", "     'training_loss': 0.36175153}\n", "train | step:   2115 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.002061327,\n", "     'cls_loss': 0.253038,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.35610437,\n", "     'total_loss': 0.35610437,\n", "     'training_loss': 0.35610437}\n", "train | step:   2160 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.00214785,\n", "     'cls_loss': 0.2560807,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.3634732,\n", "     'total_loss': 0.3634732,\n", "     'training_loss': 0.3634732}\n", " eval | step:   2160 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=15.19s).\n", "Accumulating evaluation results...\n", "DONE (t=3.91s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.684\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.527\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.516\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.567\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.146\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.691\n", " eval | step:   2160 | eval time:   59.8 sec | output: \n", "    {'AP': 0.47911617,\n", "     'AP50': 0.68407136,\n", "     'AP75': 0.5267093,\n", "     'APl': 0.5155282,\n", "     'APm': 0.032642324,\n", "     'APs': 0.0,\n", "     'ARl': 0.6914793,\n", "     'ARm': 0.14634444,\n", "     'ARmax1': 0.5665515,\n", "     'ARmax10': 0.6385077,\n", "     'ARmax100': 0.6468874,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0027877188,\n", "     'cls_loss': 0.35512033,\n", "     'model_loss': 0.49450627,\n", "     'total_loss': 0.49450627,\n", "     'validation_loss': 0.49450627}\n", "train | step:   2160 | training until step 2520...\n", "train | step:   2205 | steps/sec:    0.5 | output: \n", "    {'box_loss': 0.0020659023,\n", "     'cls_loss': 0.25056806,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.35386318,\n", "     'total_loss': 0.35386318,\n", "     'training_loss': 0.35386318}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-2205.\n", "train | step:   2250 | steps/sec:    2.0 | output: \n", "    {'box_loss': 0.0020829379,\n", "     'cls_loss': 0.2492491,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.353396,\n", "     'total_loss': 0.353396,\n", "     'training_loss': 0.353396}\n", "train | step:   2295 | steps/sec:    3.2 | output: \n", "    {'box_loss': 0.0020713964,\n", "     'cls_loss': 0.25005624,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.353626,\n", "     'total_loss': 0.353626,\n", "     'training_loss': 0.353626}\n", "train | step:   2340 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.002100987,\n", "     'cls_loss': 0.250392,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.35544133,\n", "     'total_loss': 0.35544133,\n", "     'training_loss': 0.35544133}\n", "train | step:   2385 | steps/sec:    2.5 | output: \n", "    {'box_loss': 0.0020531043,\n", "     'cls_loss': 0.24699222,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.3496474,\n", "     'total_loss': 0.3496474,\n", "     'training_loss': 0.3496474}\n", "train | step:   2430 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0021170632,\n", "     'cls_loss': 0.25197142,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.35782453,\n", "     'total_loss': 0.35782453,\n", "     'training_loss': 0.35782453}\n", "train | step:   2475 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.0020748933,\n", "     'cls_loss': 0.24476486,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.3485095,\n", "     'total_loss': 0.3485095,\n", "     'training_loss': 0.3485095}\n", "train | step:   2520 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0020252506,\n", "     'cls_loss': 0.24726908,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.34853163,\n", "     'total_loss': 0.34853163,\n", "     'training_loss': 0.34853163}\n", " eval | step:   2520 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=15.10s).\n", "Accumulating evaluation results...\n", "DONE (t=3.89s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.482\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.685\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.530\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.566\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.140\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n", " eval | step:   2520 | eval time:   59.0 sec | output: \n", "    {'AP': 0.48206875,\n", "     'AP50': 0.6847014,\n", "     'AP75': 0.53009886,\n", "     'APl': 0.5186185,\n", "     'APm': 0.033925653,\n", "     'APs': 0.0,\n", "     'ARl': 0.6933806,\n", "     'ARm': 0.13966972,\n", "     'ARmax1': 0.56610274,\n", "     'ARmax10': 0.6393364,\n", "     'ARmax100': 0.64811903,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0027638334,\n", "     'cls_loss': 0.3548692,\n", "     'model_loss': 0.4930609,\n", "     'total_loss': 0.4930609,\n", "     'validation_loss': 0.4930609}\n", "train | step:   2520 | training until step 2880...\n", "train | step:   2565 | steps/sec:    0.6 | output: \n", "    {'box_loss': 0.0020963422,\n", "     'cls_loss': 0.24770962,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.35252675,\n", "     'total_loss': 0.35252675,\n", "     'training_loss': 0.35252675}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-2565.\n", "train | step:   2610 | steps/sec:    1.8 | output: \n", "    {'box_loss': 0.0020450833,\n", "     'cls_loss': 0.24326983,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.34552407,\n", "     'total_loss': 0.34552407,\n", "     'training_loss': 0.34552407}\n", "train | step:   2655 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.002022641,\n", "     'cls_loss': 0.24196264,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.34309465,\n", "     'total_loss': 0.34309465,\n", "     'training_loss': 0.34309465}\n", "train | step:   2700 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0020764945,\n", "     'cls_loss': 0.2425917,\n", "     'learning_rate': 0.002,\n", "     'model_loss': 0.34641644,\n", "     'total_loss': 0.34641644,\n", "     'training_loss': 0.34641644}\n", "train | step:   2745 | steps/sec:    1.6 | output: \n", "    {'box_loss': 0.0020294553,\n", "     'cls_loss': 0.2424696,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34394237,\n", "     'total_loss': 0.34394237,\n", "     'training_loss': 0.34394237}\n", "train | step:   2790 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.0020826072,\n", "     'cls_loss': 0.2452983,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34942862,\n", "     'total_loss': 0.34942862,\n", "     'training_loss': 0.34942862}\n", "train | step:   2835 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.0020406775,\n", "     'cls_loss': 0.2413942,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34342813,\n", "     'total_loss': 0.34342813,\n", "     'training_loss': 0.34342813}\n", "train | step:   2880 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0020209977,\n", "     'cls_loss': 0.2402018,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.3412516,\n", "     'total_loss': 0.3412516,\n", "     'training_loss': 0.3412516}\n", " eval | step:   2880 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=17.89s).\n", "Accumulating evaluation results...\n", "DONE (t=3.91s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.485\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.688\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.534\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.567\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.648\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.140\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n", " eval | step:   2880 | eval time:   59.3 sec | output: \n", "    {'AP': 0.48485,\n", "     'AP50': 0.68774015,\n", "     'AP75': 0.53350365,\n", "     'APl': 0.5217125,\n", "     'APm': 0.032344975,\n", "     'APs': 0.0,\n", "     'ARl': 0.6932551,\n", "     'ARm': 0.13977355,\n", "     'ARmax1': 0.56677145,\n", "     'ARmax10': 0.63918793,\n", "     'ARmax100': 0.6483656,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0027573076,\n", "     'cls_loss': 0.3555705,\n", "     'model_loss': 0.49343583,\n", "     'total_loss': 0.49343583,\n", "     'validation_loss': 0.49343583}\n", "train | step:   2880 | training until step 3240...\n", "train | step:   2925 | steps/sec:    0.6 | output: \n", "    {'box_loss': 0.0020332178,\n", "     'cls_loss': 0.23853707,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34019798,\n", "     'total_loss': 0.34019798,\n", "     'training_loss': 0.34019798}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-2925.\n", "train | step:   2970 | steps/sec:    2.0 | output: \n", "    {'box_loss': 0.0020433844,\n", "     'cls_loss': 0.24184312,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34401238,\n", "     'total_loss': 0.34401238,\n", "     'training_loss': 0.34401238}\n", "train | step:   3015 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0020349852,\n", "     'cls_loss': 0.24044779,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34219706,\n", "     'total_loss': 0.34219706,\n", "     'training_loss': 0.34219706}\n", "train | step:   3060 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0020173676,\n", "     'cls_loss': 0.23912682,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.33999518,\n", "     'total_loss': 0.33999518,\n", "     'training_loss': 0.33999518}\n", "train | step:   3105 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.0019899323,\n", "     'cls_loss': 0.23810047,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.33759716,\n", "     'total_loss': 0.33759716,\n", "     'training_loss': 0.33759716}\n", "train | step:   3150 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.002006567,\n", "     'cls_loss': 0.23869275,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.33902115,\n", "     'total_loss': 0.33902115,\n", "     'training_loss': 0.33902115}\n", "train | step:   3195 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.0020608136,\n", "     'cls_loss': 0.24079113,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.3438318,\n", "     'total_loss': 0.3438318,\n", "     'training_loss': 0.3438318}\n", "train | step:   3240 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0020424982,\n", "     'cls_loss': 0.24089222,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34301707,\n", "     'total_loss': 0.34301707,\n", "     'training_loss': 0.34301707}\n", " eval | step:   3240 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=15.20s).\n", "Accumulating evaluation results...\n", "DONE (t=3.82s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.689\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.533\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.523\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.567\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.693\n", " eval | step:   3240 | eval time:   56.2 sec | output: \n", "    {'AP': 0.4862201,\n", "     'AP50': 0.6887484,\n", "     'AP75': 0.53347725,\n", "     'APl': 0.5233238,\n", "     'APm': 0.030990466,\n", "     'APs': 0.0,\n", "     'ARl': 0.6934929,\n", "     'ARm': 0.14341658,\n", "     'ARmax1': 0.5671299,\n", "     'ARmax10': 0.6393914,\n", "     'ARmax100': 0.6488783,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.0027521811,\n", "     'cls_loss': 0.353131,\n", "     'model_loss': 0.49074003,\n", "     'total_loss': 0.49074003,\n", "     'validation_loss': 0.49074003}\n", "train | step:   3240 | training until step 3600...\n", "train | step:   3285 | steps/sec:    0.5 | output: \n", "    {'box_loss': 0.0020613263,\n", "     'cls_loss': 0.23961131,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.34267753,\n", "     'total_loss': 0.34267753,\n", "     'training_loss': 0.34267753}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-3285.\n", "train | step:   3330 | steps/sec:    1.9 | output: \n", "    {'box_loss': 0.0019836922,\n", "     'cls_loss': 0.2362717,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.33545625,\n", "     'total_loss': 0.33545625,\n", "     'training_loss': 0.33545625}\n", "train | step:   3375 | steps/sec:    2.9 | output: \n", "    {'box_loss': 0.0019910694,\n", "     'cls_loss': 0.23702174,\n", "     'learning_rate': 0.001,\n", "     'model_loss': 0.33657518,\n", "     'total_loss': 0.33657518,\n", "     'training_loss': 0.33657518}\n", "train | step:   3420 | steps/sec:    3.3 | output: \n", "    {'box_loss': 0.0020088444,\n", "     'cls_loss': 0.23592363,\n", "     'learning_rate': 0.0005,\n", "     'model_loss': 0.33636585,\n", "     'total_loss': 0.33636585,\n", "     'training_loss': 0.33636585}\n", "train | step:   3465 | steps/sec:    2.3 | output: \n", "    {'box_loss': 0.0019883802,\n", "     'cls_loss': 0.23618281,\n", "     'learning_rate': 0.0005,\n", "     'model_loss': 0.33560184,\n", "     'total_loss': 0.33560184,\n", "     'training_loss': 0.33560184}\n", "train | step:   3510 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0019986914,\n", "     'cls_loss': 0.23567718,\n", "     'learning_rate': 0.0005,\n", "     'model_loss': 0.3356118,\n", "     'total_loss': 0.3356118,\n", "     'training_loss': 0.3356118}\n", "train | step:   3555 | steps/sec:    1.5 | output: \n", "    {'box_loss': 0.0020124393,\n", "     'cls_loss': 0.23597863,\n", "     'learning_rate': 0.0005,\n", "     'model_loss': 0.33660063,\n", "     'total_loss': 0.33660063,\n", "     'training_loss': 0.33660063}\n", "train | step:   3600 | steps/sec:    1.4 | output: \n", "    {'box_loss': 0.0019992497,\n", "     'cls_loss': 0.23560098,\n", "     'learning_rate': 0.0005,\n", "     'model_loss': 0.33556348,\n", "     'total_loss': 0.33556348,\n", "     'training_loss': 0.33556348}\n", " eval | step:   3600 | running 14 steps of evaluation...\n", "creating index...\n", "index created!\n", "creating index...\n", "index created!\n", "Running per image evaluation...\n", "Evaluate annotation type *bbox*\n", "DONE (t=18.02s).\n", "Accumulating evaluation results...\n", "DONE (t=3.85s).\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.488\n", " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690\n", " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.535\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n", " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.568\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.641\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.650\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.137\n", " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.695\n", " eval | step:   3600 | eval time:   60.6 sec | output: \n", "    {'AP': 0.48846987,\n", "     'AP50': 0.6900665,\n", "     'AP75': 0.5348784,\n", "     'APl': 0.52582955,\n", "     'APm': 0.032519117,\n", "     'APs': 0.0,\n", "     'ARl': 0.694866,\n", "     'ARm': 0.1367141,\n", "     'ARmax1': 0.56847763,\n", "     'ARmax10': 0.6409898,\n", "     'ARmax100': 0.64970815,\n", "     'ARs': 0.0,\n", "     'box_loss': 0.002743904,\n", "     'cls_loss': 0.35398468,\n", "     'model_loss': 0.49117988,\n", "     'total_loss': 0.49117988,\n", "     'validation_loss': 0.49117988}\n", "saved checkpoint to gs://ml1-demo-martin/arthropod_jobs/1637796032/ckpt-3600.\n"]}], "source": ["print(MODEL_DIR)\n", "model,_ = train_lib.run_experiment(\n", "    distribution_strategy=strategy,\n", "    task=task,\n", "    mode=\"train_and_eval\", # 'train', 'eval', 'train_and_eval' or 'continuous_eval'\n", "    params=params,\n", "    model_dir=MODEL_DIR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \u30e2\u30c7\u30eb\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3059\u308b  \n", "\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3055\u308c\u305f\u30e2\u30c7\u30eb\u3092\u30c6\u30b9\u30c8\u3059\u308b\u306b\u306f\u3001\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u300c04ac_retinanet_arthropods_predict.ipynb\u300d\u3092\u4f7f\u7528\u3057\u3066\u304f\u3060\u3055\u3044"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"scrolled": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["WARNING:tensorflow:Skipping full serialization of Keras layer <official.vision.beta.modeling.retinanet_model.RetinaNetModel object at 0x7f086ff9a5d0>, because it is not built.\n"]}, {"name": "stderr", "output_type": "stream", "text": ["WARNING:tensorflow:Skipping full serialization of Keras layer <official.vision.beta.modeling.retinanet_model.RetinaNetModel object at 0x7f086ff9a5d0>, because it is not built.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["WARNING:tensorflow:Skipping full serialization of Keras layer <official.vision.beta.modeling.layers.detection_generator.MultilevelDetectionGenerator object at 0x7f086c08ff50>, because it is not built.\n"]}, {"name": "stderr", "output_type": "stream", "text": ["WARNING:tensorflow:Skipping full serialization of Keras layer <official.vision.beta.modeling.layers.detection_generator.MultilevelDetectionGenerator object at 0x7f086c08ff50>, because it is not built.\n", "2021-11-25 00:07:09.126305: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n", "WARNING:absl:Found untraced functions such as inference_from_image_bytes, inference_from_tf_example, retina_net_head_1_layer_call_fn, retina_net_head_1_layer_call_and_return_conditional_losses, scores_layer_call_fn while saving (showing 5 of 597). These functions will not be directly callable after loading.\n"]}, {"name": "stdout", "output_type": "stream", "text": ["INFO:tensorflow:Assets written to: gs://ml1-demo-martin/arthropod_jobs/1637796032/saved_model/assets\n"]}, {"name": "stderr", "output_type": "stream", "text": ["INFO:tensorflow:Assets written to: gs://ml1-demo-martin/arthropod_jobs/1637796032/saved_model/assets\n"]}], "source": ["export_saved_model_lib.export_inference_graph(\n", "      input_type='image_tensor',\n", "      batch_size=4,\n", "      input_image_size=IMAGE_SIZE,\n", "      params=params,\n", "      checkpoint_path=MODEL_DIR,\n", "      export_dir=MODEL_DIR,\n", "      export_checkpoint_subdir='saved_chkpt',\n", "      export_saved_model_subdir='saved_model')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u30e9\u30a4\u30bb\u30f3\u30b9  \n", "Copyright 2021 Google Inc. Apache License\u30d0\u30fc\u30b8\u30e7\u30f32.0(\u300c\u30e9\u30a4\u30bb\u30f3\u30b9\u300d)\u306b\u57fa\u3065\u3044\u3066\u30e9\u30a4\u30bb\u30f3\u30b9\u4f9b\u4e0e\u3055\u308c\u307e\u3059\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u6e96\u62e0\u3059\u308b\u5834\u5408\u3092\u9664\u304d\u3001\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u306f\u3067\u304d\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306e\u30b3\u30d4\u30fc\u306fhttp://www.apache.org/licenses/LICENSE-2.0\u3067\u5165\u624b\u3067\u304d\u307e\u3059\u3002\u9069\u7528\u6cd5\u3067\u8981\u6c42\u3055\u308c\u3066\u3044\u308b\u304b\u3001\u66f8\u9762\u3067\u5408\u610f\u3055\u308c\u3066\u3044\u306a\u3044\u9650\u308a\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u3044\u3066\u914d\u5e03\u3055\u308c\u308b\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306f\u300c\u73fe\u72b6\u6709\u59ff\u300d\u3067\u914d\u5e03\u3055\u308c\u307e\u3059\u3002\u660e\u793a\u307e\u305f\u306f\u9ed9\u793a\u3092\u554f\u308f\u305a\u3001\u3044\u304b\u306a\u308b\u7a2e\u985e\u306e\u4fdd\u8a3c\u307e\u305f\u306f\u6761\u4ef6\u3082\u3042\u308a\u307e\u305b\u3093\u3002\u30e9\u30a4\u30bb\u30f3\u30b9\u306b\u57fa\u3065\u304f\u8a31\u53ef\u3068\u5236\u9650\u3092\u898f\u5b9a\u3059\u308b\u7279\u5b9a\u306e\u8a00\u8a9e\u306b\u3064\u3044\u3066\u306f\u3001\u30e9\u30a4\u30bb\u30f3\u30b9\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002"]}], "metadata": {"environment": {"kernel": "python3", "name": "tf2-gpu.2-8.m90", "type": "gcloud", "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m90"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.12"}}, "nbformat": 4, "nbformat_minor": 4}